{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "glove_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoCbYi4GLnoE",
        "outputId": "973f04f1-aed8-453d-d8a4-ffac53818609"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG3LvwqpN8N-"
      },
      "source": [
        "https://github.com/mwitiderrick/TensorFlow-GLOVE-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UewyTPGWMebw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttyvlLoJLsHZ"
      },
      "source": [
        "train_df = pd.read_csv('drive/My Drive/train_data.csv')\n",
        "val_df = pd.read_csv('drive/My Drive/val_data.csv')\n",
        "test_df = pd.read_csv('drive/My Drive/test_data.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXN-pJziNHuY",
        "outputId": "a09e5c37-8001-44e4-fedd-a77d4179c2b5"
      },
      "source": [
        "train_df.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'author', 'title', 'poetry_foundation_id', 'raw_content',\n",
              "       'clean_content', 'author_poem_count', 'author_poem_index',\n",
              "       'author_poem_pct'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kn6e-FqMxx2"
      },
      "source": [
        "X_train = train_df['clean_content']\n",
        "X_val = val_df['clean_content']\n",
        "X_test = test_df['clean_content']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM_5rqW5M9uj"
      },
      "source": [
        "vocab_size = 1000\n",
        "max_length = 200\n",
        "oov_token = \"<UNK>\"\n",
        "padding_type = \"post\"\n",
        "trunction_type='post'\n",
        "tokenizer = Tokenizer(num_words = vocab_size,oov_token=oov_token,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0H1SlkvNCDi"
      },
      "source": [
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_padded = pad_sequences(X_train_sequences,maxlen=max_length, padding=padding_type, \n",
        "                       truncating=trunction_type)\n",
        "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_padded = pad_sequences(X_val_sequences,maxlen=max_length, padding=padding_type, \n",
        "                       truncating=trunction_type)\n",
        "\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_padded = pad_sequences(X_test_sequences,maxlen=max_length, padding=padding_type, \n",
        "                       truncating=trunction_type)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjJlvRD4Nbt0"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_df['author'])\n",
        "y_train=le.transform(train_df['author'])\n",
        "y_val=le.transform(val_df['author'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFAbFgAHNfRG",
        "outputId": "33bff236-d3f6-4dcf-ec9f-2eec290b6e08"
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('drive/My Drive/glove.6B.200d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymlqIx9wNkOV"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, max_length))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gDMsxoRNmJ0"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            max_length,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_length,\n",
        "                            trainable=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCU9s99YNosg",
        "outputId": "8a880855-8c83-4ee7-e3cf-89c9525efa72"
      },
      "source": [
        "embedding_dim=200\n",
        "model = Sequential()\n",
        "\n",
        "model.add(embedding_layer)\n",
        "model.add(layers.Bidirectional(layers.LSTM(embedding_dim,dropout = 0.2)))\n",
        "model.add(layers.Dense(max(y_train)+1, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'SparseCategoricalCrossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 200)          3060200   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 400)               641600    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                4812      \n",
            "=================================================================\n",
            "Total params: 3,706,612\n",
            "Trainable params: 646,412\n",
            "Non-trainable params: 3,060,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VpTX7NrOCjT",
        "outputId": "76d69f4f-79f9-4206-f93e-fc16bf26dbb9"
      },
      "source": [
        "num_epochs = 100\n",
        "from keras.callbacks import EarlyStopping\n",
        "callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "history = model.fit(X_train_padded, y_train, epochs=num_epochs, validation_data=(X_val_padded, y_val),callbacks=callback)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0260 - val_accuracy: 0.3465\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0082 - val_accuracy: 0.3543\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0160 - val_accuracy: 0.3701\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0242 - val_accuracy: 0.3622\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9953 - val_accuracy: 0.3465\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9955 - val_accuracy: 0.3543\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9864 - val_accuracy: 0.3622\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.9806 - val_accuracy: 0.3465\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.9849 - val_accuracy: 0.3622\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0248 - val_accuracy: 0.3622\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0593 - val_accuracy: 0.3622\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0904 - val_accuracy: 0.3622\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1008 - val_accuracy: 0.3858\n",
            "Epoch 00013: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}