{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformers2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_LutB7z7j56",
        "outputId": "30cbdd73-c03d-426b-c064-8f15fc90df7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_CgGW5sGIi5"
      },
      "source": [
        "https://keras.io/examples/nlp/text_classification_with_transformer/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAhtIuWa_hf7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok89G0nc_wcz"
      },
      "source": [
        "pwd_train_40 = '/content/drive/MyDrive/Colab Notebooks/NLP proj/data_thresh40/train_data.csv'\n",
        "pwd_val_40 = '/content/drive/MyDrive/Colab Notebooks/NLP proj/data_thresh40/val_data.csv'\n",
        "pwd_test_40 = '/content/drive/MyDrive/Colab Notebooks/NLP proj/data_thresh40/test_data.csv'\n",
        "\n",
        "train_df = pd.read_csv(pwd_train_40)\n",
        "val_df = pd.read_csv(pwd_val_40)\n",
        "test_df = pd.read_csv(pwd_test_40)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0GzgxXi_2jm"
      },
      "source": [
        "X_train = train_df['clean_content']\n",
        "X_val = val_df['clean_content']\n",
        "X_test = test_df['clean_content']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAMvJ3cD9k5D",
        "outputId": "b5411024-0b57-4cb3-b685-9361eafe689e"
      },
      "source": [
        "#Get cleaned input sequence\n",
        "t=[]\n",
        "for i in X_train:\n",
        "  t.append(i.strip('!\"#$%&()*+,-.–—/:;<=>?@[\\\\]^_`{|}~\\t\\r\\n'))       \n",
        "v=[]\n",
        "for i in X_val:\n",
        "  v.append(i.strip('!\"#$%&()*+,-.–—/:;<=>?@[\\\\]^_`{|}~\\t\\r\\n'))\n",
        "e=[]\n",
        "for i in X_test:\n",
        "  e.append(i.strip('!\"#$%&()*+,-.–—/:;<=>?@[\\\\]^_`{|}~\\t\\r\\n'))\n",
        "\n",
        "x_train=[]\n",
        "for i in range(len(t)):\n",
        "  x_train.append(' '.join(t[i].split('\\n')))\n",
        "x_val=[]\n",
        "for i in range(len(v)):\n",
        "  x_val.append(' '.join(v[i].split('\\n')))\n",
        "x_test=[]\n",
        "for i in range(len(e)):\n",
        "  x_test.append(' '.join(e[i].split('\\n')))\n",
        "print(len(x_train),len(x_val),len(x_test))\n",
        "\n",
        "x_train = [i.split(' ') for i in x_train]\n",
        "x_test = [i.split(' ') for i in x_test]\n",
        "xv=[]\n",
        "for i in x_val:\n",
        "  xv.append(i.split(' '))\n",
        "x_val=xv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "457 127 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64jT1KGa9pzv",
        "outputId": "643c737d-7da2-4c15-9e14-e316d5990835"
      },
      "source": [
        "#check input\n",
        "print(x_train[4])\n",
        "print(x_val[5])\n",
        "print(x_test[2])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sometim', 'someth', 'like', 'second', 'wash', 'base', 'street', 'th', 'father', 'two', 'assistants', 'ar', 'given', 'permiss', 'go', 'on', 'woman', 'ask', '“why', 'did', 'come', 'first', 'place', 'to', 'citadel', 'dampness”', '', 'som', 'day', 'wors', 'others', 'even', \"can't\", 'believ', 'them', 'but', 'never', 'concern', 'mine', 'reason', 'patient', '', 's', 'scroll', 'never', 'blast', 'us', 'into', 'marmor', 'mean', 'fist', 'it', 'kudo', 'princ', 'journey', 'here', 'to', 'negoti', 'releas', 'believ', 'it', '', \"you'r\", 'right', 'ballad', 'retreating', 'back', 'atmosphere', 'they', \"won't\", 'come', 'round', 'again', 'mak', 'peac']\n",
            "['mani', 'time', 'low', 'foot', 'stagger', 'solder', 'mouth', 'tell', 'tri', 'stir', 'aw', 'rivet', 'tri', 'lift', 'hasp', 'steel', '', 'strok', 'cool', 'forehead', 'hot', 'often', 'lift', 'care', 'listless', 'hair', 'handl', 'adamantin', 'fingers', 'nev', 'thimbl', 'shall', 'wear', 'buzz', 'dull', 'fli', 'chamber', 'window', 'brave', 'shine', 'sun', 'freckl', 'pane', 'fearless', 'cobweb', 'swing', 'ceil', 'indol', 'housewif', 'daisi', 'lain']\n",
            "['storm', 'past', 'storm', 'tyrann', 'rage', 'a', 'stupid', 'calm', 'noth', 'doth', 'suage', 'th', 'fabl', 'invert', 'far', 'more', 'a', 'block', 'afflict', 'stork', 'before', 'storm', 'chafe', 'soon', 'wear', 'us', 'in', 'calm', 'heaven', 'laugh', 'see', 'u', 'languish', 'thus', 'a', 'steadya', 'wish', 'thought', 'were', 'smooth', 'thi', 'mistress', 'glass', 'shine', 'there', 'th', 'sea', 'isl', 'we', 'seek', 'move', 'ship', 'root', 'be', 'a', 'water', 'storm', 'pitch', 'run', 'out', 'a', 'lead', 'fird', 'church', 'becom', 'one', 'spout', 'and', 'beauti', 'trim', 'decays', 'lik', 'court', 'remov', 'like', 'end', 'plays', 'th', 'fightingplac', 'seaman', 'rag', 'supply', 'and', 'tackl', 'frippery', 'no', 'use', 'lanthorn', 'one', 'place', 'lay', 'feath', 'dust', 'today', 'yesterday', 'earth', 'hollow', 'world', 'lung', 'are', 'hav', 'wind', 'upper', 'vault', 'air', 'w', 'lost', 'friend', 'sought', 'foe', 'recover', 'but', 'meteorlik', 'save', 'move', 'hover', 'on', 'calentur', 'togeth', 'draws', 'dear', 'friend', 'meet', 'dead', 'great', 'fish', 'jaws', 'and', 'hatch', 'altar', 'lies', 'each', 'one', 'priest', 'sacrifice', 'who', 'live', 'miracl', 'multiply', 'wher', 'walker', 'hot', 'oven', 'die', 'if', 'despit', 'swim', 'hath', 'no', 'refresh', 'brimston', 'bath', 'but', 'sea', 'ship', 'turn', 'lik', 'parboild', 'wretch', 'coal', 'burn', 'lik', 'bajazet', 'encagd', 'shepherd', 'scoff', 'or', 'like', 'slacksinewd', 'samson', 'hair', 'off', 'languish', 'ship', 'myriad', 'of', 'ant', 'durst', 'th', 'emperor', 'lovd', 'snake', 'invade', 'th', 'crawl', 'galli', 'seagaol', 'finni', 'chips', 'might', 'brave', 'pinnac', 'bedrid', 'ships', 'wheth', 'rotten', 'state', 'hope', 'gain', 'or', 'disus', 'queasi', 'pain', 'of', 'belovd', 'love', 'thirst', 'of', 'honour', 'fair', 'death', 'outpushd', 'first', 'i', 'lose', 'end', 'well', 'i', 'a', 'desper', 'may', 'live', 'coward', 'die', 'stag', 'dog', 'toward', 'flies', 'i', 'paid', 'life', 'prey', 'dies', 'fat', 'grudg', 'u', 'doth', 'subt', 'lay', 'a', 'scourg', 'gainst', 'forget', 'pray', 'h', 'sea', 'pray', 'wind', 'well', 'und', 'pole', 'may', 'beg', 'cold', 'heat', 'hell', 'what', 'littl', 'alas', 'i', 'man', 'was', 'noth', 'u', 'noth', 'fit', 'chanc', 'still', 'disproport', 'it', 'w', 'power', 'sens', 'lie', 'i', 'thus', 'feel', 'miseri']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwH6569tDgGl",
        "outputId": "001a2a44-49d1-4143-9c49-9232f1219623"
      },
      "source": [
        "#(Optional) Splitting input sequence\n",
        "max_len = 150\n",
        "author_train=[]\n",
        "poem_train=[]\n",
        "for k in range(len(x_train)):\n",
        "  x = x_train[k]\n",
        "  if len(x) > max_len:  #Can choose different length\n",
        "    chunks, chunk_size = len(x), max_len\n",
        "    a=[x[i:i+int(chunk_size)] for i in range(0, int(chunks), int(chunk_size)) ]\n",
        "    for j in a:\n",
        "      poem_train.append(j)\n",
        "      author_train.append(train_df['author'][k])\n",
        "  else:\n",
        "    poem_train.append(x)\n",
        "    author_train.append(train_df['author'][k])\n",
        "\n",
        "author_val=[]\n",
        "poem_val=[]\n",
        "for k in range(len(x_val)):\n",
        "  x = x_val[k]\n",
        "  if len(x) > max_len:\n",
        "    chunks, chunk_size = len(x), max_len\n",
        "    a=[x[i:i+int(chunk_size)] for i in range(0, int(chunks), int(chunk_size)) ]\n",
        "    for j in a:\n",
        "      poem_val.append(j)\n",
        "      author_val.append(val_df['author'][k])\n",
        "  else:\n",
        "    poem_val.append(x)\n",
        "    author_val.append(val_df['author'][k])\n",
        "\n",
        "author_test=[]\n",
        "poem_test=[]\n",
        "for k in range(len(x_test)):\n",
        "  x = x_test[k]\n",
        "  if len(x) > max_len:\n",
        "    chunks, chunk_size = len(x), max_len\n",
        "    a=[x[i:i+int(chunk_size)] for i in range(0, int(chunks), int(chunk_size)) ]\n",
        "    for j in a:\n",
        "      poem_test.append(j)\n",
        "      author_test.append(test_df['author'][k])\n",
        "  else:\n",
        "    poem_test.append(x)\n",
        "    author_test.append(test_df['author'][k])\n",
        "\n",
        "print(len(author_train)==len(poem_train))\n",
        "print(len(author_val)==len(poem_val))    \n",
        "print(len(author_test)==len(poem_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVg2-05CDjLQ",
        "outputId": "c5c6e8bd-ff8e-4de7-a404-46af611c08c4"
      },
      "source": [
        "#Check distribution\n",
        "from collections import Counter\n",
        "Counter(author_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Alfred, Lord Tennyson': 151,\n",
              "         'Emily Dickinson': 40,\n",
              "         'John Ashbery': 57,\n",
              "         'John Donne': 56,\n",
              "         'Kay Ryan': 29,\n",
              "         'Percy sshe Shelley': 110,\n",
              "         'Rae Armantrout': 46,\n",
              "         'Walt Whitman': 128,\n",
              "         'William Butler Yeats': 46,\n",
              "         'William Shakespeare': 109,\n",
              "         'William Wordsworth': 106,\n",
              "         'Yusef Komunyakaa': 37})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhiGf8i_DmiV",
        "outputId": "feb27266-f2ed-4361-ed33-93cf5ea8ec54"
      },
      "source": [
        "# Tokenize the dataset\n",
        "MAX_NB_WORDS = 50000\n",
        "oov_token = \"<UNK>\"\n",
        "padding_type = \"post\"\n",
        "trunction_type='post'\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, oov_token=oov_token,filters='!\"#$%&()*+,-–./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r')\n",
        "tokenizer.fit_on_texts(poem_train)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15310 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIoQmiPSF4yD"
      },
      "source": [
        "X_train_sequences = tokenizer.texts_to_sequences(poem_train)\n",
        "X_train_padded = pad_sequences(X_train_sequences, padding=padding_type, \n",
        "                       truncating=trunction_type)\n",
        "X_val_sequences = tokenizer.texts_to_sequences(poem_val)\n",
        "X_val_padded = pad_sequences(X_val_sequences, padding=padding_type,\n",
        "                       truncating=trunction_type)\n",
        "\n",
        "X_test_sequences = tokenizer.texts_to_sequences(poem_test)\n",
        "X_test_padded = pad_sequences(X_test_sequences, padding=padding_type, \n",
        "                       truncating=trunction_type)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewIbFwPlF5uG",
        "outputId": "48e7d397-c599-4118-b7ee-44c1a55597aa"
      },
      "source": [
        "X_train_padded.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(915, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOShDYPm_9rD"
      },
      "source": [
        "#Encode label to numbers  (Use 'SparseCategoricalCrossentropy' if using numbers)\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(author_train)\n",
        "y_train=le.transform(author_train)\n",
        "y_val=le.transform(author_val)\n",
        "y_test=le.transform(author_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuvfGimlLPe4",
        "outputId": "6cd7fa93-5669-4abf-9c24-43d905531b1c"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(915,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zg06zDDAMXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105659dd-7391-40b2-d36d-1038a71c689f"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "to_categorical(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlDB13SyLUUr",
        "outputId": "4e68c646-a219-4b1c-949a-d2411d73ab86"
      },
      "source": [
        "to_categorical(y_train).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(915, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi8jzeIWLavN"
      },
      "source": [
        "#didn't run \n",
        "#(Optional)One hot encoding   (Use 'categorical_crossentropy' if using one hot)\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90ISLLaWATiK"
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F32xp6lpAX34"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-NQ5e_oAZnh"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr5q-vfeOFxw"
      },
      "source": [
        "w/o lr decay, max_len = 150,dim = 32, num_heads = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFyVeQ7zAchg"
      },
      "source": [
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "nclasses = 12\n",
        "max_length = 150\n",
        "\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_length, MAX_NB_WORDS, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(nclasses, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuw_N73-Ba6X"
      },
      "source": [
        "#lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "#    initial_learning_rate=1e-2,\n",
        "#    decay_steps=10000,\n",
        "#    decay_rate=0.9)\n",
        "#opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "#model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.compile('adam', \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9DQRrS9GWHQ",
        "outputId": "ff81bf1d-87d4-4cc4-d333-68ff4ec8a510"
      },
      "source": [
        "#run 1\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=30, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "29/29 [==============================] - 7s 226ms/step - loss: 2.4058 - accuracy: 0.1650 - val_loss: 2.5276 - val_accuracy: 0.0479\n",
            "Epoch 2/30\n",
            "29/29 [==============================] - 6s 215ms/step - loss: 2.0492 - accuracy: 0.2929 - val_loss: 2.2573 - val_accuracy: 0.1809\n",
            "Epoch 3/30\n",
            "29/29 [==============================] - 6s 212ms/step - loss: 1.6036 - accuracy: 0.4437 - val_loss: 2.0604 - val_accuracy: 0.3138\n",
            "Epoch 4/30\n",
            "29/29 [==============================] - 6s 212ms/step - loss: 1.1108 - accuracy: 0.6164 - val_loss: 1.8304 - val_accuracy: 0.3617\n",
            "Epoch 5/30\n",
            "29/29 [==============================] - 6s 211ms/step - loss: 0.8108 - accuracy: 0.7268 - val_loss: 1.6793 - val_accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "29/29 [==============================] - 6s 216ms/step - loss: 0.4775 - accuracy: 0.8426 - val_loss: 1.7462 - val_accuracy: 0.5319\n",
            "Epoch 7/30\n",
            "29/29 [==============================] - 6s 213ms/step - loss: 0.3128 - accuracy: 0.9027 - val_loss: 1.6328 - val_accuracy: 0.6064\n",
            "Epoch 8/30\n",
            "29/29 [==============================] - 6s 212ms/step - loss: 0.1868 - accuracy: 0.9421 - val_loss: 1.6021 - val_accuracy: 0.6117\n",
            "Epoch 9/30\n",
            "29/29 [==============================] - 6s 212ms/step - loss: 0.1247 - accuracy: 0.9705 - val_loss: 2.0236 - val_accuracy: 0.5426\n",
            "Epoch 10/30\n",
            "29/29 [==============================] - 6s 212ms/step - loss: 0.0801 - accuracy: 0.9803 - val_loss: 2.0985 - val_accuracy: 0.5691\n",
            "Epoch 11/30\n",
            "29/29 [==============================] - 6s 211ms/step - loss: 0.0626 - accuracy: 0.9847 - val_loss: 2.1676 - val_accuracy: 0.5798\n",
            "Epoch 12/30\n",
            "29/29 [==============================] - 6s 211ms/step - loss: 0.0482 - accuracy: 0.9880 - val_loss: 2.0622 - val_accuracy: 0.5851\n",
            "Epoch 13/30\n",
            "29/29 [==============================] - 6s 212ms/step - loss: 0.0384 - accuracy: 0.9934 - val_loss: 2.1388 - val_accuracy: 0.5745\n",
            "Epoch 14/30\n",
            "29/29 [==============================] - 6s 213ms/step - loss: 0.0337 - accuracy: 0.9945 - val_loss: 2.1889 - val_accuracy: 0.5957\n",
            "Epoch 15/30\n",
            "29/29 [==============================] - 6s 211ms/step - loss: 0.0376 - accuracy: 0.9869 - val_loss: 2.5855 - val_accuracy: 0.5213\n",
            "Epoch 16/30\n",
            "29/29 [==============================] - 6s 212ms/step - loss: 0.0286 - accuracy: 0.9934 - val_loss: 2.3746 - val_accuracy: 0.5957\n",
            "Epoch 17/30\n",
            "29/29 [==============================] - 6s 211ms/step - loss: 0.0306 - accuracy: 0.9880 - val_loss: 2.3233 - val_accuracy: 0.5745\n",
            "Epoch 18/30\n",
            "29/29 [==============================] - 6s 211ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 2.1952 - val_accuracy: 0.6170\n",
            "Epoch 19/30\n",
            "29/29 [==============================] - 6s 210ms/step - loss: 0.0141 - accuracy: 0.9989 - val_loss: 2.2812 - val_accuracy: 0.5957\n",
            "Epoch 20/30\n",
            "29/29 [==============================] - 6s 210ms/step - loss: 0.0120 - accuracy: 0.9989 - val_loss: 2.5903 - val_accuracy: 0.5638\n",
            "Epoch 21/30\n",
            "29/29 [==============================] - 6s 211ms/step - loss: 0.0123 - accuracy: 0.9978 - val_loss: 2.4131 - val_accuracy: 0.5585\n",
            "Epoch 22/30\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.3618 - val_accuracy: 0.6011\n",
            "Epoch 23/30\n",
            "29/29 [==============================] - 7s 236ms/step - loss: 0.0158 - accuracy: 0.9978 - val_loss: 2.4792 - val_accuracy: 0.5851\n",
            "Epoch 24/30\n",
            "29/29 [==============================] - 6s 211ms/step - loss: 0.0110 - accuracy: 0.9989 - val_loss: 2.4391 - val_accuracy: 0.5904\n",
            "Epoch 25/30\n",
            "29/29 [==============================] - 6s 210ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 2.3299 - val_accuracy: 0.6170\n",
            "Epoch 26/30\n",
            "29/29 [==============================] - 6s 210ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 2.9688 - val_accuracy: 0.5213\n",
            "Epoch 27/30\n",
            "29/29 [==============================] - 6s 209ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 2.4000 - val_accuracy: 0.6170\n",
            "Epoch 28/30\n",
            "29/29 [==============================] - 6s 208ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 3.0800 - val_accuracy: 0.4894\n",
            "Epoch 29/30\n",
            "29/29 [==============================] - 6s 210ms/step - loss: 0.0116 - accuracy: 0.9989 - val_loss: 2.5575 - val_accuracy: 0.6117\n",
            "Epoch 30/30\n",
            "29/29 [==============================] - 6s 210ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5102 - val_accuracy: 0.6383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NfgswwUN9VB",
        "outputId": "b7b7a06f-d3e1-484d-de9d-e32df043f6dc"
      },
      "source": [
        "#run 2\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=30, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "29/29 [==============================] - 3s 100ms/step - loss: 2.3990 - accuracy: 0.1344 - val_loss: 2.3836 - val_accuracy: 0.1170\n",
            "Epoch 2/30\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 2.1917 - accuracy: 0.2317 - val_loss: 2.3803 - val_accuracy: 0.1383\n",
            "Epoch 3/30\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 1.8384 - accuracy: 0.4022 - val_loss: 2.0140 - val_accuracy: 0.3883\n",
            "Epoch 4/30\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 1.3707 - accuracy: 0.5836 - val_loss: 1.8432 - val_accuracy: 0.3723\n",
            "Epoch 5/30\n",
            "29/29 [==============================] - 4s 145ms/step - loss: 1.0113 - accuracy: 0.6721 - val_loss: 1.6584 - val_accuracy: 0.4043\n",
            "Epoch 6/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.7694 - accuracy: 0.7814 - val_loss: 1.4580 - val_accuracy: 0.5053\n",
            "Epoch 7/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.5261 - accuracy: 0.8623 - val_loss: 1.3498 - val_accuracy: 0.5426\n",
            "Epoch 8/30\n",
            "29/29 [==============================] - 3s 90ms/step - loss: 0.3970 - accuracy: 0.9016 - val_loss: 1.4530 - val_accuracy: 0.5691\n",
            "Epoch 9/30\n",
            "29/29 [==============================] - 3s 90ms/step - loss: 0.2911 - accuracy: 0.9421 - val_loss: 1.2844 - val_accuracy: 0.6223\n",
            "Epoch 10/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.2272 - accuracy: 0.9552 - val_loss: 1.6248 - val_accuracy: 0.5638\n",
            "Epoch 11/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.2082 - accuracy: 0.9497 - val_loss: 1.1378 - val_accuracy: 0.6702\n",
            "Epoch 12/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.1630 - accuracy: 0.9694 - val_loss: 1.3645 - val_accuracy: 0.5851\n",
            "Epoch 13/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.1283 - accuracy: 0.9705 - val_loss: 1.4352 - val_accuracy: 0.5426\n",
            "Epoch 14/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.1413 - accuracy: 0.9705 - val_loss: 1.6536 - val_accuracy: 0.5053\n",
            "Epoch 15/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.0868 - accuracy: 0.9847 - val_loss: 1.5764 - val_accuracy: 0.6223\n",
            "Epoch 16/30\n",
            "29/29 [==============================] - 3s 87ms/step - loss: 0.1053 - accuracy: 0.9749 - val_loss: 1.5570 - val_accuracy: 0.5585\n",
            "Epoch 17/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0754 - accuracy: 0.9836 - val_loss: 1.9730 - val_accuracy: 0.5213\n",
            "Epoch 18/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0615 - accuracy: 0.9902 - val_loss: 1.6790 - val_accuracy: 0.5638\n",
            "Epoch 19/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.0468 - accuracy: 0.9902 - val_loss: 1.4598 - val_accuracy: 0.6011\n",
            "Epoch 20/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0362 - accuracy: 0.9934 - val_loss: 1.4518 - val_accuracy: 0.6117\n",
            "Epoch 21/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0303 - accuracy: 0.9934 - val_loss: 1.4308 - val_accuracy: 0.6383\n",
            "Epoch 22/30\n",
            "29/29 [==============================] - 3s 90ms/step - loss: 0.0282 - accuracy: 0.9978 - val_loss: 1.5426 - val_accuracy: 0.6011\n",
            "Epoch 23/30\n",
            "29/29 [==============================] - 3s 91ms/step - loss: 0.0264 - accuracy: 0.9978 - val_loss: 1.4677 - val_accuracy: 0.6436\n",
            "Epoch 24/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.0230 - accuracy: 0.9978 - val_loss: 1.5917 - val_accuracy: 0.6277\n",
            "Epoch 25/30\n",
            "29/29 [==============================] - 3s 91ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 1.5938 - val_accuracy: 0.6330\n",
            "Epoch 26/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0256 - accuracy: 0.9967 - val_loss: 1.6532 - val_accuracy: 0.6170\n",
            "Epoch 27/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.0195 - accuracy: 0.9956 - val_loss: 1.7075 - val_accuracy: 0.6170\n",
            "Epoch 28/30\n",
            "29/29 [==============================] - 3s 91ms/step - loss: 0.0162 - accuracy: 0.9989 - val_loss: 1.5326 - val_accuracy: 0.6436\n",
            "Epoch 29/30\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.0197 - accuracy: 0.9967 - val_loss: 1.5041 - val_accuracy: 0.6809\n",
            "Epoch 30/30\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0180 - accuracy: 0.9978 - val_loss: 1.6679 - val_accuracy: 0.5957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4rIfYrpj_Wv",
        "outputId": "28eb6b96-b439-459c-e7aa-b80f095654ec"
      },
      "source": [
        "model.evaluate(X_test_padded, y_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 30ms/step - loss: 2.6893 - accuracy: 0.2600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.6892850399017334, 0.25999999046325684]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX4hcErHq14K"
      },
      "source": [
        "authors = list(set(author_train))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rva0A3BruUO"
      },
      "source": [
        "authors = sorted(authors)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFQs4QsmpP3T",
        "outputId": "61a0e489-05fc-4774-ab9a-3b55b0100197"
      },
      "source": [
        "for i in range(12):\n",
        "  print (authors[i])\n",
        "  ind = np.where(y_test == i)\n",
        "  X = X_test_padded[ind]\n",
        "  y = y_test[ind]\n",
        "  model.evaluate(X, y)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alfred, Lord Tennyson\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8214 - accuracy: 0.6000\n",
            "Emily Dickinson\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.3337 - accuracy: 0.2000\n",
            "John Ashbery\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4439 - accuracy: 0.0000e+00\n",
            "John Donne\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3935 - accuracy: 0.6000\n",
            "Kay Ryan\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5769 - accuracy: 0.0000e+00\n",
            "Percy sshe Shelley\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0196 - accuracy: 0.2258\n",
            "Rae Armantrout\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9568 - accuracy: 0.5000\n",
            "Walt Whitman\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8129 - accuracy: 0.0000e+00\n",
            "William Butler Yeats\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0221 - accuracy: 0.4000\n",
            "William Shakespeare\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8035 - accuracy: 0.3750\n",
            "William Wordsworth\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9964 - accuracy: 0.1667\n",
            "Yusef Komunyakaa\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0803 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxHgBhibe3s1",
        "outputId": "c5e455e3-1eac-41b7-b21d-be2f8875075e"
      },
      "source": [
        "#run 3\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=40, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "29/29 [==============================] - 3s 96ms/step - loss: 2.4758 - accuracy: 0.1290 - val_loss: 2.4026 - val_accuracy: 0.1436\n",
            "Epoch 2/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 2.2199 - accuracy: 0.2317 - val_loss: 2.3484 - val_accuracy: 0.1330\n",
            "Epoch 3/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 1.8766 - accuracy: 0.4142 - val_loss: 2.2240 - val_accuracy: 0.1862\n",
            "Epoch 4/40\n",
            "29/29 [==============================] - 2s 85ms/step - loss: 1.3804 - accuracy: 0.5683 - val_loss: 1.9379 - val_accuracy: 0.3085\n",
            "Epoch 5/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 1.0109 - accuracy: 0.6940 - val_loss: 1.7065 - val_accuracy: 0.4255\n",
            "Epoch 6/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.7635 - accuracy: 0.7694 - val_loss: 1.7372 - val_accuracy: 0.3936\n",
            "Epoch 7/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.5779 - accuracy: 0.8393 - val_loss: 1.6172 - val_accuracy: 0.4628\n",
            "Epoch 8/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.4591 - accuracy: 0.8776 - val_loss: 1.6036 - val_accuracy: 0.4947\n",
            "Epoch 9/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.3562 - accuracy: 0.9082 - val_loss: 1.6510 - val_accuracy: 0.4787\n",
            "Epoch 10/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.2867 - accuracy: 0.9377 - val_loss: 1.6079 - val_accuracy: 0.5372\n",
            "Epoch 11/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.2505 - accuracy: 0.9421 - val_loss: 1.9672 - val_accuracy: 0.4734\n",
            "Epoch 12/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.2445 - accuracy: 0.9333 - val_loss: 2.2982 - val_accuracy: 0.4628\n",
            "Epoch 13/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.2203 - accuracy: 0.9486 - val_loss: 1.9392 - val_accuracy: 0.5000\n",
            "Epoch 14/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.1787 - accuracy: 0.9454 - val_loss: 1.8424 - val_accuracy: 0.4681\n",
            "Epoch 15/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.1232 - accuracy: 0.9727 - val_loss: 2.0016 - val_accuracy: 0.4840\n",
            "Epoch 16/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.1511 - accuracy: 0.9574 - val_loss: 1.8677 - val_accuracy: 0.5532\n",
            "Epoch 17/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.1482 - accuracy: 0.9574 - val_loss: 1.9215 - val_accuracy: 0.5319\n",
            "Epoch 18/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.1247 - accuracy: 0.9694 - val_loss: 2.1230 - val_accuracy: 0.4681\n",
            "Epoch 19/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.0973 - accuracy: 0.9749 - val_loss: 1.7272 - val_accuracy: 0.5745\n",
            "Epoch 20/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.0631 - accuracy: 0.9869 - val_loss: 1.9561 - val_accuracy: 0.5479\n",
            "Epoch 21/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.0447 - accuracy: 0.9923 - val_loss: 1.9200 - val_accuracy: 0.5372\n",
            "Epoch 22/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.0383 - accuracy: 0.9967 - val_loss: 2.0137 - val_accuracy: 0.5479\n",
            "Epoch 23/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.0386 - accuracy: 0.9945 - val_loss: 2.0457 - val_accuracy: 0.5585\n",
            "Epoch 24/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.0375 - accuracy: 0.9945 - val_loss: 2.1703 - val_accuracy: 0.5479\n",
            "Epoch 25/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.0355 - accuracy: 0.9967 - val_loss: 2.0286 - val_accuracy: 0.5532\n",
            "Epoch 26/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.0232 - accuracy: 0.9978 - val_loss: 2.0955 - val_accuracy: 0.5479\n",
            "Epoch 27/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.0256 - accuracy: 0.9978 - val_loss: 2.0941 - val_accuracy: 0.5798\n",
            "Epoch 28/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 2.3284 - val_accuracy: 0.5319\n",
            "Epoch 29/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.0201 - accuracy: 0.9967 - val_loss: 2.2011 - val_accuracy: 0.5638\n",
            "Epoch 30/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.0256 - accuracy: 0.9967 - val_loss: 2.2154 - val_accuracy: 0.5372\n",
            "Epoch 31/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.0221 - accuracy: 0.9967 - val_loss: 2.1600 - val_accuracy: 0.5798\n",
            "Epoch 32/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.0186 - accuracy: 0.9989 - val_loss: 2.2828 - val_accuracy: 0.5585\n",
            "Epoch 33/40\n",
            "29/29 [==============================] - 2s 85ms/step - loss: 0.0265 - accuracy: 0.9945 - val_loss: 2.3556 - val_accuracy: 0.5638\n",
            "Epoch 34/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.0184 - accuracy: 0.9978 - val_loss: 2.0771 - val_accuracy: 0.5957\n",
            "Epoch 35/40\n",
            "29/29 [==============================] - 2s 82ms/step - loss: 0.0171 - accuracy: 0.9967 - val_loss: 2.2678 - val_accuracy: 0.5957\n",
            "Epoch 36/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 2.2400 - val_accuracy: 0.5585\n",
            "Epoch 37/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.0176 - accuracy: 0.9967 - val_loss: 2.5836 - val_accuracy: 0.5266\n",
            "Epoch 38/40\n",
            "29/29 [==============================] - 2s 84ms/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 2.3340 - val_accuracy: 0.5319\n",
            "Epoch 39/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 2.5395 - val_accuracy: 0.5319\n",
            "Epoch 40/40\n",
            "29/29 [==============================] - 2s 83ms/step - loss: 0.0099 - accuracy: 0.9989 - val_loss: 2.3799 - val_accuracy: 0.5638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUI551r4fuXF"
      },
      "source": [
        "w/o lr decay, max_len = 150,dim = 64, num_heads = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvJu0illfu50"
      },
      "source": [
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "nclasses = 12\n",
        "max_length = 150\n",
        "\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_length, MAX_NB_WORDS, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(nclasses, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXaEtKZbfz0_"
      },
      "source": [
        "#lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "#    initial_learning_rate=1e-2,\n",
        "#    decay_steps=10000,\n",
        "#    decay_rate=0.9)\n",
        "#opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "#model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.compile('adam', \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87vzU3BHgB6K",
        "outputId": "438e2edc-5c8f-4c4d-db6e-4da584c01a37"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=40, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "29/29 [==============================] - 4s 133ms/step - loss: 2.3357 - accuracy: 0.1475 - val_loss: 2.3416 - val_accuracy: 0.2021\n",
            "Epoch 2/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 2.0916 - accuracy: 0.2863 - val_loss: 2.1950 - val_accuracy: 0.3245\n",
            "Epoch 3/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 1.6030 - accuracy: 0.5344 - val_loss: 1.8978 - val_accuracy: 0.3670\n",
            "Epoch 4/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 1.0749 - accuracy: 0.6852 - val_loss: 1.5503 - val_accuracy: 0.4681\n",
            "Epoch 5/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.6485 - accuracy: 0.8077 - val_loss: 1.7051 - val_accuracy: 0.4521\n",
            "Epoch 6/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 0.4721 - accuracy: 0.8634 - val_loss: 1.3954 - val_accuracy: 0.5957\n",
            "Epoch 7/40\n",
            "29/29 [==============================] - 4s 124ms/step - loss: 0.3403 - accuracy: 0.9104 - val_loss: 1.2219 - val_accuracy: 0.6170\n",
            "Epoch 8/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 0.2329 - accuracy: 0.9410 - val_loss: 1.4519 - val_accuracy: 0.5798\n",
            "Epoch 9/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.1743 - accuracy: 0.9574 - val_loss: 1.1919 - val_accuracy: 0.6330\n",
            "Epoch 10/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 0.0949 - accuracy: 0.9836 - val_loss: 1.2100 - val_accuracy: 0.6596\n",
            "Epoch 11/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0649 - accuracy: 0.9891 - val_loss: 1.2754 - val_accuracy: 0.6809\n",
            "Epoch 12/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0577 - accuracy: 0.9858 - val_loss: 1.6243 - val_accuracy: 0.6011\n",
            "Epoch 13/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0433 - accuracy: 0.9934 - val_loss: 1.3787 - val_accuracy: 0.6277\n",
            "Epoch 14/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0356 - accuracy: 0.9956 - val_loss: 1.4152 - val_accuracy: 0.6649\n",
            "Epoch 15/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0279 - accuracy: 0.9956 - val_loss: 1.4039 - val_accuracy: 0.6543\n",
            "Epoch 16/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0282 - accuracy: 0.9934 - val_loss: 1.3827 - val_accuracy: 0.6702\n",
            "Epoch 17/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0211 - accuracy: 0.9967 - val_loss: 1.4541 - val_accuracy: 0.6702\n",
            "Epoch 18/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 0.0179 - accuracy: 0.9967 - val_loss: 1.5490 - val_accuracy: 0.6702\n",
            "Epoch 19/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0215 - accuracy: 0.9967 - val_loss: 1.5389 - val_accuracy: 0.6489\n",
            "Epoch 20/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 1.5961 - val_accuracy: 0.6596\n",
            "Epoch 21/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 1.5515 - val_accuracy: 0.6649\n",
            "Epoch 22/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0122 - accuracy: 0.9989 - val_loss: 1.6306 - val_accuracy: 0.6755\n",
            "Epoch 23/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6426 - val_accuracy: 0.6968\n",
            "Epoch 24/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 1.8119 - val_accuracy: 0.6596\n",
            "Epoch 25/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5922 - val_accuracy: 0.6809\n",
            "Epoch 26/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 1.5972 - val_accuracy: 0.6862\n",
            "Epoch 27/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 1.6822 - val_accuracy: 0.6489\n",
            "Epoch 28/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 1.7923 - val_accuracy: 0.6702\n",
            "Epoch 29/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 1.7148 - val_accuracy: 0.6702\n",
            "Epoch 30/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 2.0150 - val_accuracy: 0.6330\n",
            "Epoch 31/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 1.7505 - val_accuracy: 0.6702\n",
            "Epoch 32/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.7167 - val_accuracy: 0.6862\n",
            "Epoch 33/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.8228 - val_accuracy: 0.6755\n",
            "Epoch 34/40\n",
            "29/29 [==============================] - 4s 125ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 1.7271 - val_accuracy: 0.6755\n",
            "Epoch 35/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.6809\n",
            "Epoch 36/40\n",
            "29/29 [==============================] - 4s 124ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 1.8543 - val_accuracy: 0.6489\n",
            "Epoch 37/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 1.7459 - val_accuracy: 0.6809\n",
            "Epoch 38/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.8526 - val_accuracy: 0.6755\n",
            "Epoch 39/40\n",
            "29/29 [==============================] - 4s 124ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.8497 - val_accuracy: 0.6809\n",
            "Epoch 40/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 1.9147 - val_accuracy: 0.6436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHjy4EYHsI66"
      },
      "source": [
        "w/o lr decay, max_len = 150,dim = 64, num_heads = 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyH_OITKro1x",
        "outputId": "c8ae08b5-9cd5-43ba-96ab-112373f0d4cb"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=40, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "29/29 [==============================] - 3s 116ms/step - loss: 2.3087 - accuracy: 0.1989 - val_loss: 2.3134 - val_accuracy: 0.1968\n",
            "Epoch 2/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 1.9141 - accuracy: 0.3639 - val_loss: 2.1415 - val_accuracy: 0.3457\n",
            "Epoch 3/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 1.4234 - accuracy: 0.5443 - val_loss: 1.9115 - val_accuracy: 0.3245\n",
            "Epoch 4/40\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.9921 - accuracy: 0.6995 - val_loss: 1.6582 - val_accuracy: 0.4574\n",
            "Epoch 5/40\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.6076 - accuracy: 0.8295 - val_loss: 1.5283 - val_accuracy: 0.5000\n",
            "Epoch 6/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.4331 - accuracy: 0.8896 - val_loss: 1.4212 - val_accuracy: 0.5426\n",
            "Epoch 7/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.3132 - accuracy: 0.9137 - val_loss: 1.2843 - val_accuracy: 0.5904\n",
            "Epoch 8/40\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.2062 - accuracy: 0.9486 - val_loss: 1.3385 - val_accuracy: 0.5851\n",
            "Epoch 9/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1275 - accuracy: 0.9705 - val_loss: 1.1014 - val_accuracy: 0.6649\n",
            "Epoch 10/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0811 - accuracy: 0.9825 - val_loss: 1.2573 - val_accuracy: 0.6436\n",
            "Epoch 11/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0486 - accuracy: 0.9934 - val_loss: 1.1954 - val_accuracy: 0.6330\n",
            "Epoch 12/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0313 - accuracy: 0.9967 - val_loss: 1.2025 - val_accuracy: 0.6277\n",
            "Epoch 13/40\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0351 - accuracy: 0.9945 - val_loss: 1.2666 - val_accuracy: 0.6489\n",
            "Epoch 14/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0240 - accuracy: 0.9967 - val_loss: 1.2067 - val_accuracy: 0.6543\n",
            "Epoch 15/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0214 - accuracy: 0.9967 - val_loss: 1.2167 - val_accuracy: 0.6543\n",
            "Epoch 16/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0205 - accuracy: 0.9978 - val_loss: 1.3816 - val_accuracy: 0.6543\n",
            "Epoch 17/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 0.6755\n",
            "Epoch 18/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 1.2843 - val_accuracy: 0.6489\n",
            "Epoch 19/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 1.2904 - val_accuracy: 0.6436\n",
            "Epoch 20/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 1.4240 - val_accuracy: 0.6489\n",
            "Epoch 21/40\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 1.2948 - val_accuracy: 0.6489\n",
            "Epoch 22/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 1.3120 - val_accuracy: 0.6436\n",
            "Epoch 23/40\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.3484 - val_accuracy: 0.6596\n",
            "Epoch 24/40\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 1.3976 - val_accuracy: 0.6436\n",
            "Epoch 25/40\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 1.4454 - val_accuracy: 0.6436\n",
            "Epoch 26/40\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 1.3839 - val_accuracy: 0.6383\n",
            "Epoch 27/40\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 1.4099 - val_accuracy: 0.6330\n",
            "Epoch 28/40\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 1.3681 - val_accuracy: 0.6596\n",
            "Epoch 29/40\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 1.4129 - val_accuracy: 0.6489\n",
            "Epoch 30/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.4457 - val_accuracy: 0.6543\n",
            "Epoch 31/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4225 - val_accuracy: 0.6755\n",
            "Epoch 32/40\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.4574 - val_accuracy: 0.6489\n",
            "Epoch 33/40\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.4570 - val_accuracy: 0.6596\n",
            "Epoch 34/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 1.5773 - val_accuracy: 0.6277\n",
            "Epoch 35/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6843 - val_accuracy: 0.6277\n",
            "Epoch 36/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 1.7305 - val_accuracy: 0.6117\n",
            "Epoch 37/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.8397 - val_accuracy: 0.6170\n",
            "Epoch 38/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6070 - val_accuracy: 0.6543\n",
            "Epoch 39/40\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7042 - val_accuracy: 0.6436\n",
            "Epoch 40/40\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7829 - val_accuracy: 0.6277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0rlM3Its_MJ"
      },
      "source": [
        "w/o lr decay, max_len = 150,dim = 128, num_heads = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74EL6zXps-nU",
        "outputId": "d5ee25a6-b7b4-4226-d1d4-2fd49a22103f"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "29/29 [==============================] - 7s 232ms/step - loss: 2.3103 - accuracy: 0.1749 - val_loss: 2.3649 - val_accuracy: 0.1596\n",
            "Epoch 2/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 1.8363 - accuracy: 0.3530 - val_loss: 2.0743 - val_accuracy: 0.2819\n",
            "Epoch 3/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 1.3337 - accuracy: 0.5607 - val_loss: 1.7562 - val_accuracy: 0.3883\n",
            "Epoch 4/25\n",
            "29/29 [==============================] - 6s 220ms/step - loss: 0.8714 - accuracy: 0.7158 - val_loss: 1.6192 - val_accuracy: 0.4362\n",
            "Epoch 5/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.5323 - accuracy: 0.8426 - val_loss: 1.7111 - val_accuracy: 0.4362\n",
            "Epoch 6/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.3649 - accuracy: 0.8863 - val_loss: 1.4080 - val_accuracy: 0.5266\n",
            "Epoch 7/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.2117 - accuracy: 0.9388 - val_loss: 1.7084 - val_accuracy: 0.4894\n",
            "Epoch 8/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.1264 - accuracy: 0.9705 - val_loss: 1.4842 - val_accuracy: 0.5851\n",
            "Epoch 9/25\n",
            "29/29 [==============================] - 7s 224ms/step - loss: 0.0698 - accuracy: 0.9792 - val_loss: 1.6559 - val_accuracy: 0.5798\n",
            "Epoch 10/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0491 - accuracy: 0.9869 - val_loss: 1.6394 - val_accuracy: 0.5638\n",
            "Epoch 11/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0323 - accuracy: 0.9945 - val_loss: 1.5947 - val_accuracy: 0.6277\n",
            "Epoch 12/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0281 - accuracy: 0.9945 - val_loss: 1.6158 - val_accuracy: 0.6223\n",
            "Epoch 13/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0220 - accuracy: 0.9967 - val_loss: 1.6157 - val_accuracy: 0.6436\n",
            "Epoch 14/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 1.8333 - val_accuracy: 0.6064\n",
            "Epoch 15/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 1.6034 - val_accuracy: 0.6543\n",
            "Epoch 16/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 2.0187 - val_accuracy: 0.5957\n",
            "Epoch 17/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 1.9148 - val_accuracy: 0.5745\n",
            "Epoch 18/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0164 - accuracy: 0.9978 - val_loss: 1.6713 - val_accuracy: 0.6383\n",
            "Epoch 19/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 1.7227 - val_accuracy: 0.6277\n",
            "Epoch 20/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 2.0751 - val_accuracy: 0.5904\n",
            "Epoch 21/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.7050 - val_accuracy: 0.6489\n",
            "Epoch 22/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 1.7294 - val_accuracy: 0.6702\n",
            "Epoch 23/25\n",
            "29/29 [==============================] - 7s 226ms/step - loss: 0.0177 - accuracy: 0.9967 - val_loss: 2.1951 - val_accuracy: 0.6117\n",
            "Epoch 24/25\n",
            "29/29 [==============================] - 7s 233ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.9815 - val_accuracy: 0.5904\n",
            "Epoch 25/25\n",
            "29/29 [==============================] - 7s 232ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 1.7960 - val_accuracy: 0.6809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWpl2VwUuJx_"
      },
      "source": [
        "with lr decay, max_len = 150,dim = 128, num_heads = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqKzNQaBuJFF"
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9)\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAHxLT8Iu6rq",
        "outputId": "c7762bb9-9785-448e-c0e9-6336f8ec82e8"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "29/29 [==============================] - 7s 232ms/step - loss: 2.4251 - accuracy: 0.1377 - val_loss: 2.3907 - val_accuracy: 0.1809\n",
            "Epoch 2/25\n",
            "29/29 [==============================] - 6s 220ms/step - loss: 2.1420 - accuracy: 0.2197 - val_loss: 2.3137 - val_accuracy: 0.1383\n",
            "Epoch 3/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 1.9879 - accuracy: 0.2754 - val_loss: 2.1588 - val_accuracy: 0.2872\n",
            "Epoch 4/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 1.7653 - accuracy: 0.3607 - val_loss: 2.1651 - val_accuracy: 0.2447\n",
            "Epoch 5/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 1.6681 - accuracy: 0.3934 - val_loss: 2.0865 - val_accuracy: 0.2447\n",
            "Epoch 6/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 1.5096 - accuracy: 0.4383 - val_loss: 1.9808 - val_accuracy: 0.2766\n",
            "Epoch 7/25\n",
            "29/29 [==============================] - 6s 218ms/step - loss: 1.4133 - accuracy: 0.4754 - val_loss: 2.1417 - val_accuracy: 0.2553\n",
            "Epoch 8/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 1.3249 - accuracy: 0.5104 - val_loss: 2.1125 - val_accuracy: 0.2766\n",
            "Epoch 9/25\n",
            "29/29 [==============================] - 6s 218ms/step - loss: 1.2356 - accuracy: 0.5377 - val_loss: 2.2317 - val_accuracy: 0.3191\n",
            "Epoch 10/25\n",
            "29/29 [==============================] - 6s 219ms/step - loss: 1.1801 - accuracy: 0.5749 - val_loss: 2.2754 - val_accuracy: 0.2979\n",
            "Epoch 11/25\n",
            "29/29 [==============================] - 6s 220ms/step - loss: 1.0906 - accuracy: 0.6175 - val_loss: 2.7347 - val_accuracy: 0.2872\n",
            "Epoch 12/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 1.0709 - accuracy: 0.6033 - val_loss: 2.4870 - val_accuracy: 0.2553\n",
            "Epoch 13/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 1.0735 - accuracy: 0.6153 - val_loss: 2.2651 - val_accuracy: 0.3032\n",
            "Epoch 14/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.9994 - accuracy: 0.6404 - val_loss: 2.6169 - val_accuracy: 0.3085\n",
            "Epoch 15/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.9471 - accuracy: 0.6645 - val_loss: 2.5662 - val_accuracy: 0.2872\n",
            "Epoch 16/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.9389 - accuracy: 0.6699 - val_loss: 2.9198 - val_accuracy: 0.3191\n",
            "Epoch 17/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.8556 - accuracy: 0.6820 - val_loss: 2.2221 - val_accuracy: 0.3457\n",
            "Epoch 18/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.7480 - accuracy: 0.7213 - val_loss: 2.9392 - val_accuracy: 0.3245\n",
            "Epoch 19/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.7825 - accuracy: 0.7311 - val_loss: 2.7402 - val_accuracy: 0.3457\n",
            "Epoch 20/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.8135 - accuracy: 0.7148 - val_loss: 3.3305 - val_accuracy: 0.2660\n",
            "Epoch 21/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.8157 - accuracy: 0.7104 - val_loss: 2.7687 - val_accuracy: 0.2979\n",
            "Epoch 22/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.7552 - accuracy: 0.7180 - val_loss: 2.5372 - val_accuracy: 0.3457\n",
            "Epoch 23/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.6760 - accuracy: 0.7257 - val_loss: 2.7510 - val_accuracy: 0.2500\n",
            "Epoch 24/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.5949 - accuracy: 0.7672 - val_loss: 3.0823 - val_accuracy: 0.3404\n",
            "Epoch 25/25\n",
            "29/29 [==============================] - 6s 220ms/step - loss: 0.5469 - accuracy: 0.8131 - val_loss: 3.1708 - val_accuracy: 0.3191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04FTbcFWv6-R"
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9)\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUmOAYD3v6n3",
        "outputId": "f90fb7a1-0064-40d1-b238-4ea1c6371311"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "29/29 [==============================] - 7s 242ms/step - loss: 2.3882 - accuracy: 0.1257 - val_loss: 2.3977 - val_accuracy: 0.1117\n",
            "Epoch 2/25\n",
            "29/29 [==============================] - 7s 239ms/step - loss: 2.0083 - accuracy: 0.3246 - val_loss: 2.1628 - val_accuracy: 0.2234\n",
            "Epoch 3/25\n",
            "29/29 [==============================] - 11s 390ms/step - loss: 1.4364 - accuracy: 0.5093 - val_loss: 1.7435 - val_accuracy: 0.4149\n",
            "Epoch 4/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.8508 - accuracy: 0.7432 - val_loss: 1.4645 - val_accuracy: 0.5160\n",
            "Epoch 5/25\n",
            "29/29 [==============================] - 6s 220ms/step - loss: 0.4635 - accuracy: 0.8623 - val_loss: 1.6009 - val_accuracy: 0.4894\n",
            "Epoch 6/25\n",
            "29/29 [==============================] - 6s 220ms/step - loss: 0.2878 - accuracy: 0.9148 - val_loss: 1.3396 - val_accuracy: 0.5691\n",
            "Epoch 7/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.1530 - accuracy: 0.9585 - val_loss: 1.4219 - val_accuracy: 0.6064\n",
            "Epoch 8/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.1337 - accuracy: 0.9574 - val_loss: 1.4989 - val_accuracy: 0.5745\n",
            "Epoch 9/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0858 - accuracy: 0.9781 - val_loss: 1.4721 - val_accuracy: 0.5798\n",
            "Epoch 10/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0624 - accuracy: 0.9858 - val_loss: 1.6000 - val_accuracy: 0.6011\n",
            "Epoch 11/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0474 - accuracy: 0.9880 - val_loss: 1.6508 - val_accuracy: 0.5851\n",
            "Epoch 12/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0442 - accuracy: 0.9913 - val_loss: 1.5202 - val_accuracy: 0.6170\n",
            "Epoch 13/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0365 - accuracy: 0.9923 - val_loss: 1.8093 - val_accuracy: 0.6170\n",
            "Epoch 14/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0272 - accuracy: 0.9934 - val_loss: 1.7235 - val_accuracy: 0.6117\n",
            "Epoch 15/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 1.9276 - val_accuracy: 0.5745\n",
            "Epoch 16/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0258 - accuracy: 0.9934 - val_loss: 1.7445 - val_accuracy: 0.6383\n",
            "Epoch 17/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0285 - accuracy: 0.9945 - val_loss: 1.8286 - val_accuracy: 0.6223\n",
            "Epoch 18/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0197 - accuracy: 0.9967 - val_loss: 2.0550 - val_accuracy: 0.5851\n",
            "Epoch 19/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0260 - accuracy: 0.9967 - val_loss: 1.7452 - val_accuracy: 0.6011\n",
            "Epoch 20/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0153 - accuracy: 0.9978 - val_loss: 2.0768 - val_accuracy: 0.5957\n",
            "Epoch 21/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 1.9361 - val_accuracy: 0.6277\n",
            "Epoch 22/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 2.1240 - val_accuracy: 0.6277\n",
            "Epoch 23/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 2.0736 - val_accuracy: 0.6064\n",
            "Epoch 24/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 2.2470 - val_accuracy: 0.6011\n",
            "Epoch 25/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 2.1218 - val_accuracy: 0.6117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M52YWquew7Fd"
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C32ldT9hw-ca",
        "outputId": "214c82a2-b05a-4b06-b5af-bd688fffc5d4"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "29/29 [==============================] - 7s 235ms/step - loss: 2.2867 - accuracy: 0.1672 - val_loss: 2.3329 - val_accuracy: 0.1968\n",
            "Epoch 2/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 1.8709 - accuracy: 0.3322 - val_loss: 2.1371 - val_accuracy: 0.2234\n",
            "Epoch 3/25\n",
            "29/29 [==============================] - 6s 220ms/step - loss: 1.3090 - accuracy: 0.5355 - val_loss: 1.8750 - val_accuracy: 0.3457\n",
            "Epoch 4/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.9384 - accuracy: 0.6743 - val_loss: 2.0346 - val_accuracy: 0.3245\n",
            "Epoch 5/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.7904 - accuracy: 0.7454 - val_loss: 1.6706 - val_accuracy: 0.4309\n",
            "Epoch 6/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.5042 - accuracy: 0.8437 - val_loss: 1.5174 - val_accuracy: 0.5213\n",
            "Epoch 7/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.3101 - accuracy: 0.9082 - val_loss: 1.3280 - val_accuracy: 0.5691\n",
            "Epoch 8/25\n",
            "29/29 [==============================] - 7s 226ms/step - loss: 0.1985 - accuracy: 0.9464 - val_loss: 1.5546 - val_accuracy: 0.5266\n",
            "Epoch 9/25\n",
            "29/29 [==============================] - 11s 363ms/step - loss: 0.1377 - accuracy: 0.9607 - val_loss: 1.3147 - val_accuracy: 0.6117\n",
            "Epoch 10/25\n",
            "29/29 [==============================] - 7s 237ms/step - loss: 0.0972 - accuracy: 0.9705 - val_loss: 1.5194 - val_accuracy: 0.5904\n",
            "Epoch 11/25\n",
            "29/29 [==============================] - 7s 233ms/step - loss: 0.0619 - accuracy: 0.9836 - val_loss: 1.7111 - val_accuracy: 0.6064\n",
            "Epoch 12/25\n",
            "29/29 [==============================] - 7s 224ms/step - loss: 0.0654 - accuracy: 0.9847 - val_loss: 1.8217 - val_accuracy: 0.5426\n",
            "Epoch 13/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0482 - accuracy: 0.9923 - val_loss: 1.7747 - val_accuracy: 0.5798\n",
            "Epoch 14/25\n",
            "29/29 [==============================] - 7s 226ms/step - loss: 0.0338 - accuracy: 0.9923 - val_loss: 1.8847 - val_accuracy: 0.5957\n",
            "Epoch 15/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0280 - accuracy: 0.9956 - val_loss: 2.3312 - val_accuracy: 0.5213\n",
            "Epoch 16/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0263 - accuracy: 0.9956 - val_loss: 1.8532 - val_accuracy: 0.6011\n",
            "Epoch 17/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0241 - accuracy: 0.9956 - val_loss: 1.7695 - val_accuracy: 0.6170\n",
            "Epoch 18/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0229 - accuracy: 0.9945 - val_loss: 1.9409 - val_accuracy: 0.6277\n",
            "Epoch 19/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 2.0572 - val_accuracy: 0.6170\n",
            "Epoch 20/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 1.8981 - val_accuracy: 0.6117\n",
            "Epoch 21/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0247 - accuracy: 0.9934 - val_loss: 2.2632 - val_accuracy: 0.5691\n",
            "Epoch 22/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 1.9796 - val_accuracy: 0.6064\n",
            "Epoch 23/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 1.9663 - val_accuracy: 0.6011\n",
            "Epoch 24/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 2.4315 - val_accuracy: 0.5372\n",
            "Epoch 25/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 2.0751 - val_accuracy: 0.6064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ngw8ClQyBwj"
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=100,\n",
        "    decay_rate=0.9)\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrGKXnzAyEdd",
        "outputId": "683cd939-df07-4b60-e99b-58253a9c3638"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "29/29 [==============================] - 7s 234ms/step - loss: 2.3233 - accuracy: 0.1967 - val_loss: 2.4101 - val_accuracy: 0.1011\n",
            "Epoch 2/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 1.8642 - accuracy: 0.3268 - val_loss: 2.2243 - val_accuracy: 0.2128\n",
            "Epoch 3/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 1.4654 - accuracy: 0.4798 - val_loss: 2.0250 - val_accuracy: 0.3245\n",
            "Epoch 4/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 1.0587 - accuracy: 0.6426 - val_loss: 1.7950 - val_accuracy: 0.4415\n",
            "Epoch 5/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.6896 - accuracy: 0.7661 - val_loss: 1.8636 - val_accuracy: 0.4787\n",
            "Epoch 6/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.4459 - accuracy: 0.8601 - val_loss: 1.5842 - val_accuracy: 0.4894\n",
            "Epoch 7/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.2932 - accuracy: 0.9082 - val_loss: 1.3430 - val_accuracy: 0.5851\n",
            "Epoch 8/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.1953 - accuracy: 0.9333 - val_loss: 1.6329 - val_accuracy: 0.5691\n",
            "Epoch 9/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.1430 - accuracy: 0.9585 - val_loss: 1.6399 - val_accuracy: 0.5479\n",
            "Epoch 10/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0949 - accuracy: 0.9727 - val_loss: 1.5554 - val_accuracy: 0.5957\n",
            "Epoch 11/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0714 - accuracy: 0.9825 - val_loss: 1.5623 - val_accuracy: 0.6489\n",
            "Epoch 12/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0460 - accuracy: 0.9913 - val_loss: 1.8317 - val_accuracy: 0.6223\n",
            "Epoch 13/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0335 - accuracy: 0.9923 - val_loss: 1.8905 - val_accuracy: 0.6436\n",
            "Epoch 14/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 1.8670 - val_accuracy: 0.6436\n",
            "Epoch 15/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0221 - accuracy: 0.9967 - val_loss: 1.8294 - val_accuracy: 0.6543\n",
            "Epoch 16/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0146 - accuracy: 0.9978 - val_loss: 1.8109 - val_accuracy: 0.6702\n",
            "Epoch 17/25\n",
            "29/29 [==============================] - 7s 233ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 1.9260 - val_accuracy: 0.6543\n",
            "Epoch 18/25\n",
            "29/29 [==============================] - 6s 219ms/step - loss: 0.0220 - accuracy: 0.9956 - val_loss: 1.9201 - val_accuracy: 0.6543\n",
            "Epoch 19/25\n",
            "29/29 [==============================] - 7s 229ms/step - loss: 0.0131 - accuracy: 0.9989 - val_loss: 1.9202 - val_accuracy: 0.6383\n",
            "Epoch 20/25\n",
            "29/29 [==============================] - 7s 229ms/step - loss: 0.0152 - accuracy: 0.9978 - val_loss: 1.9366 - val_accuracy: 0.6436\n",
            "Epoch 21/25\n",
            "29/29 [==============================] - 7s 232ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 2.1390 - val_accuracy: 0.6170\n",
            "Epoch 22/25\n",
            "29/29 [==============================] - 7s 224ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 1.9854 - val_accuracy: 0.6489\n",
            "Epoch 23/25\n",
            "29/29 [==============================] - 6s 220ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 2.1116 - val_accuracy: 0.6277\n",
            "Epoch 24/25\n",
            "29/29 [==============================] - 6s 221ms/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 2.1100 - val_accuracy: 0.6223\n",
            "Epoch 25/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 2.0462 - val_accuracy: 0.6596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m1E4ogi1A26"
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=150,\n",
        "    decay_rate=1)\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoDY9Ctg1DQ1",
        "outputId": "13d19a29-4772-42f5-c0d4-b71bb4e29bd3"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "29/29 [==============================] - 7s 241ms/step - loss: 0.0146 - accuracy: 0.9978 - val_loss: 2.6886 - val_accuracy: 0.5957\n",
            "Epoch 2/25\n",
            "29/29 [==============================] - 7s 224ms/step - loss: 0.0210 - accuracy: 0.9956 - val_loss: 2.6163 - val_accuracy: 0.6011\n",
            "Epoch 3/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 2.4874 - val_accuracy: 0.6489\n",
            "Epoch 4/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 2.5111 - val_accuracy: 0.6702\n",
            "Epoch 5/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 2.6654 - val_accuracy: 0.6489\n",
            "Epoch 6/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 2.6052 - val_accuracy: 0.6436\n",
            "Epoch 7/25\n",
            "29/29 [==============================] - 7s 227ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 3.1937 - val_accuracy: 0.5851\n",
            "Epoch 8/25\n",
            "29/29 [==============================] - 7s 227ms/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 2.6420 - val_accuracy: 0.6436\n",
            "Epoch 9/25\n",
            "29/29 [==============================] - 7s 224ms/step - loss: 0.0112 - accuracy: 0.9978 - val_loss: 3.9681 - val_accuracy: 0.5691\n",
            "Epoch 10/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0385 - accuracy: 0.9869 - val_loss: 3.6845 - val_accuracy: 0.5479\n",
            "Epoch 11/25\n",
            "29/29 [==============================] - 7s 224ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 3.8654 - val_accuracy: 0.5691\n",
            "Epoch 12/25\n",
            "29/29 [==============================] - 7s 224ms/step - loss: 0.0644 - accuracy: 0.9847 - val_loss: 2.9780 - val_accuracy: 0.6277\n",
            "Epoch 13/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0330 - accuracy: 0.9923 - val_loss: 3.0239 - val_accuracy: 0.6330\n",
            "Epoch 14/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 2.2933 - val_accuracy: 0.6649\n",
            "Epoch 15/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 2.5878 - val_accuracy: 0.6809\n",
            "Epoch 16/25\n",
            "29/29 [==============================] - 7s 226ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 3.0168 - val_accuracy: 0.6596\n",
            "Epoch 17/25\n",
            "29/29 [==============================] - 7s 226ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.7152 - val_accuracy: 0.6755\n",
            "Epoch 18/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 2.6350 - val_accuracy: 0.6702\n",
            "Epoch 19/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 2.6522 - val_accuracy: 0.6702\n",
            "Epoch 20/25\n",
            "29/29 [==============================] - 7s 226ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.7649 - val_accuracy: 0.6809\n",
            "Epoch 21/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0059 - accuracy: 0.9967 - val_loss: 2.7271 - val_accuracy: 0.6809\n",
            "Epoch 22/25\n",
            "29/29 [==============================] - 6s 223ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.6387 - val_accuracy: 0.6702\n",
            "Epoch 23/25\n",
            "29/29 [==============================] - 6s 222ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.7091 - val_accuracy: 0.6915\n",
            "Epoch 24/25\n",
            "29/29 [==============================] - 6s 224ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 3.7007 - val_accuracy: 0.6277\n",
            "Epoch 25/25\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 2.7776 - val_accuracy: 0.6809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuCYm6_93vr1"
      },
      "source": [
        "with lr decay, max_len = 200, dim = 128, num_heads = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3Ia6tzZ3tt9"
      },
      "source": [
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "nclasses = 12\n",
        "max_length = 200\n",
        "\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_length, MAX_NB_WORDS, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(nclasses, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyyEvE9K4ZFx"
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=200,\n",
        "    decay_rate=1)\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ioR439k4d7r",
        "outputId": "2685ae84-b954-432d-eeb8-c863c1cb2b4f"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=40, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "25/25 [==============================] - 8s 303ms/step - loss: 2.3809 - accuracy: 0.1688 - val_loss: 2.3878 - val_accuracy: 0.2229\n",
            "Epoch 2/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 2.1127 - accuracy: 0.2668 - val_loss: 2.3590 - val_accuracy: 0.1446\n",
            "Epoch 3/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 1.7051 - accuracy: 0.4253 - val_loss: 2.1779 - val_accuracy: 0.1988\n",
            "Epoch 4/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 1.3108 - accuracy: 0.5438 - val_loss: 2.2924 - val_accuracy: 0.2651\n",
            "Epoch 5/40\n",
            "25/25 [==============================] - 7s 290ms/step - loss: 0.9531 - accuracy: 0.6843 - val_loss: 1.8892 - val_accuracy: 0.3434\n",
            "Epoch 6/40\n",
            "25/25 [==============================] - 7s 290ms/step - loss: 0.6167 - accuracy: 0.7874 - val_loss: 1.6403 - val_accuracy: 0.4518\n",
            "Epoch 7/40\n",
            "25/25 [==============================] - 7s 285ms/step - loss: 0.3411 - accuracy: 0.8982 - val_loss: 1.5332 - val_accuracy: 0.4940\n",
            "Epoch 8/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.2154 - accuracy: 0.9446 - val_loss: 1.5023 - val_accuracy: 0.5301\n",
            "Epoch 9/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.1233 - accuracy: 0.9742 - val_loss: 1.4850 - val_accuracy: 0.5602\n",
            "Epoch 10/40\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0786 - accuracy: 0.9871 - val_loss: 1.6652 - val_accuracy: 0.5482\n",
            "Epoch 11/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0575 - accuracy: 0.9884 - val_loss: 1.5678 - val_accuracy: 0.5904\n",
            "Epoch 12/40\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0436 - accuracy: 0.9936 - val_loss: 1.7058 - val_accuracy: 0.5542\n",
            "Epoch 13/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0336 - accuracy: 0.9974 - val_loss: 1.6951 - val_accuracy: 0.5964\n",
            "Epoch 14/40\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0354 - accuracy: 0.9897 - val_loss: 1.6172 - val_accuracy: 0.6265\n",
            "Epoch 15/40\n",
            "25/25 [==============================] - 7s 285ms/step - loss: 0.0196 - accuracy: 0.9974 - val_loss: 1.6821 - val_accuracy: 0.6265\n",
            "Epoch 16/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0169 - accuracy: 0.9987 - val_loss: 1.6462 - val_accuracy: 0.6084\n",
            "Epoch 17/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 1.8261 - val_accuracy: 0.5964\n",
            "Epoch 18/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0193 - accuracy: 0.9974 - val_loss: 1.6690 - val_accuracy: 0.6145\n",
            "Epoch 19/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 1.8439 - val_accuracy: 0.6265\n",
            "Epoch 20/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0184 - accuracy: 0.9961 - val_loss: 1.9223 - val_accuracy: 0.6205\n",
            "Epoch 21/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.9170 - val_accuracy: 0.6205\n",
            "Epoch 22/40\n",
            "25/25 [==============================] - 7s 285ms/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 1.9055 - val_accuracy: 0.6325\n",
            "Epoch 23/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 2.0719 - val_accuracy: 0.6024\n",
            "Epoch 24/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0161 - accuracy: 0.9987 - val_loss: 2.0088 - val_accuracy: 0.6265\n",
            "Epoch 25/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 1.9228 - val_accuracy: 0.6265\n",
            "Epoch 26/40\n",
            "25/25 [==============================] - 7s 295ms/step - loss: 0.0214 - accuracy: 0.9961 - val_loss: 1.8745 - val_accuracy: 0.6145\n",
            "Epoch 27/40\n",
            "25/25 [==============================] - 7s 292ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 2.3658 - val_accuracy: 0.5422\n",
            "Epoch 28/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 2.0300 - val_accuracy: 0.6084\n",
            "Epoch 29/40\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 2.0350 - val_accuracy: 0.6627\n",
            "Epoch 30/40\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 1.9661 - val_accuracy: 0.6386\n",
            "Epoch 31/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.1656 - val_accuracy: 0.6024\n",
            "Epoch 32/40\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 2.2071 - val_accuracy: 0.6084\n",
            "Epoch 33/40\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 2.2155 - val_accuracy: 0.6265\n",
            "Epoch 34/40\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 2.0589 - val_accuracy: 0.6386\n",
            "Epoch 35/40\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1292 - val_accuracy: 0.6084\n",
            "Epoch 36/40\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 2.0814 - val_accuracy: 0.6386\n",
            "Epoch 37/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 2.0388 - val_accuracy: 0.6386\n",
            "Epoch 38/40\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 2.1542 - val_accuracy: 0.6265\n",
            "Epoch 39/40\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1835 - val_accuracy: 0.6325\n",
            "Epoch 40/40\n",
            "25/25 [==============================] - 7s 290ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.0367 - val_accuracy: 0.6386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2wI1EDQAFG8"
      },
      "source": [
        "w/o lr decay, max_len = 200, dim = 128, num_heads = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNtPGUGmMARi"
      },
      "source": [
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "nclasses = 12\n",
        "max_length = 200\n",
        "\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_length, MAX_NB_WORDS, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(nclasses, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg7f7QQM-7WY"
      },
      "source": [
        "model.compile('adam', \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RtBCDll_Drx",
        "outputId": "f55d82ae-5f40-41e2-b307-92ca6a662be2"
      },
      "source": [
        "# run 1\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "25/25 [==============================] - 7s 299ms/step - loss: 2.3807 - accuracy: 0.1430 - val_loss: 2.3377 - val_accuracy: 0.1506\n",
            "Epoch 2/25\n",
            "25/25 [==============================] - 7s 283ms/step - loss: 2.0525 - accuracy: 0.2642 - val_loss: 2.2315 - val_accuracy: 0.2349\n",
            "Epoch 3/25\n",
            "25/25 [==============================] - 7s 285ms/step - loss: 1.6810 - accuracy: 0.4394 - val_loss: 2.0335 - val_accuracy: 0.2530\n",
            "Epoch 4/25\n",
            "25/25 [==============================] - 7s 284ms/step - loss: 1.3839 - accuracy: 0.5103 - val_loss: 1.9282 - val_accuracy: 0.2771\n",
            "Epoch 5/25\n",
            "25/25 [==============================] - 7s 285ms/step - loss: 1.0836 - accuracy: 0.6237 - val_loss: 1.6227 - val_accuracy: 0.4458\n",
            "Epoch 6/25\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.7157 - accuracy: 0.7668 - val_loss: 1.5508 - val_accuracy: 0.5482\n",
            "Epoch 7/25\n",
            "25/25 [==============================] - 7s 284ms/step - loss: 0.4070 - accuracy: 0.8763 - val_loss: 1.2664 - val_accuracy: 0.6506\n",
            "Epoch 8/25\n",
            "25/25 [==============================] - 7s 285ms/step - loss: 0.1710 - accuracy: 0.9626 - val_loss: 1.2850 - val_accuracy: 0.6627\n",
            "Epoch 9/25\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0982 - accuracy: 0.9781 - val_loss: 1.1701 - val_accuracy: 0.6928\n",
            "Epoch 10/25\n",
            "25/25 [==============================] - 7s 284ms/step - loss: 0.0752 - accuracy: 0.9807 - val_loss: 1.2406 - val_accuracy: 0.6687\n",
            "Epoch 11/25\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0434 - accuracy: 0.9884 - val_loss: 1.2032 - val_accuracy: 0.6867\n",
            "Epoch 12/25\n",
            "25/25 [==============================] - 7s 292ms/step - loss: 0.0360 - accuracy: 0.9974 - val_loss: 1.2538 - val_accuracy: 0.7108\n",
            "Epoch 13/25\n",
            "25/25 [==============================] - 7s 296ms/step - loss: 0.0343 - accuracy: 0.9910 - val_loss: 1.2415 - val_accuracy: 0.6988\n",
            "Epoch 14/25\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0251 - accuracy: 0.9974 - val_loss: 1.5526 - val_accuracy: 0.6205\n",
            "Epoch 15/25\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0253 - accuracy: 0.9948 - val_loss: 1.3572 - val_accuracy: 0.6687\n",
            "Epoch 16/25\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3042 - val_accuracy: 0.7108\n",
            "Epoch 17/25\n",
            "25/25 [==============================] - 7s 285ms/step - loss: 0.0142 - accuracy: 0.9987 - val_loss: 1.4337 - val_accuracy: 0.6988\n",
            "Epoch 18/25\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4216 - val_accuracy: 0.6988\n",
            "Epoch 19/25\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0128 - accuracy: 0.9987 - val_loss: 1.4138 - val_accuracy: 0.6747\n",
            "Epoch 20/25\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 1.4327 - val_accuracy: 0.6988\n",
            "Epoch 21/25\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 1.7307 - val_accuracy: 0.6145\n",
            "Epoch 22/25\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.2560 - val_accuracy: 0.7169\n",
            "Epoch 23/25\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 1.3453 - val_accuracy: 0.6988\n",
            "Epoch 24/25\n",
            "25/25 [==============================] - 7s 285ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 1.3704 - val_accuracy: 0.7229\n",
            "Epoch 25/25\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 1.7855 - val_accuracy: 0.6205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK_-QpzrMFZ0",
        "outputId": "9f56f649-1d37-4076-958a-95f271cf4ac4"
      },
      "source": [
        "# run 2\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "25/25 [==============================] - 8s 300ms/step - loss: 2.3203 - accuracy: 0.1559 - val_loss: 2.3278 - val_accuracy: 0.1566\n",
            "Epoch 2/25\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 2.0382 - accuracy: 0.2977 - val_loss: 2.2145 - val_accuracy: 0.3072\n",
            "Epoch 3/25\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 1.6704 - accuracy: 0.4304 - val_loss: 2.0630 - val_accuracy: 0.2952\n",
            "Epoch 4/25\n",
            "25/25 [==============================] - 7s 290ms/step - loss: 1.3053 - accuracy: 0.5709 - val_loss: 1.7473 - val_accuracy: 0.4578\n",
            "Epoch 5/25\n",
            "25/25 [==============================] - 7s 291ms/step - loss: 0.9477 - accuracy: 0.6740 - val_loss: 1.3738 - val_accuracy: 0.5422\n",
            "Epoch 6/25\n",
            "25/25 [==============================] - 7s 290ms/step - loss: 0.5424 - accuracy: 0.8325 - val_loss: 1.5209 - val_accuracy: 0.5422\n",
            "Epoch 7/25\n",
            "25/25 [==============================] - 7s 291ms/step - loss: 0.3161 - accuracy: 0.9124 - val_loss: 1.2113 - val_accuracy: 0.6205\n",
            "Epoch 8/25\n",
            "25/25 [==============================] - 7s 291ms/step - loss: 0.1635 - accuracy: 0.9536 - val_loss: 1.1918 - val_accuracy: 0.6205\n",
            "Epoch 9/25\n",
            "25/25 [==============================] - 7s 291ms/step - loss: 0.1132 - accuracy: 0.9768 - val_loss: 1.1530 - val_accuracy: 0.6627\n",
            "Epoch 10/25\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0703 - accuracy: 0.9871 - val_loss: 1.1609 - val_accuracy: 0.6807\n",
            "Epoch 11/25\n",
            "25/25 [==============================] - 7s 295ms/step - loss: 0.0661 - accuracy: 0.9832 - val_loss: 1.3354 - val_accuracy: 0.6446\n",
            "Epoch 12/25\n",
            "25/25 [==============================] - 8s 302ms/step - loss: 0.0498 - accuracy: 0.9897 - val_loss: 1.4617 - val_accuracy: 0.6325\n",
            "Epoch 13/25\n",
            "25/25 [==============================] - 8s 300ms/step - loss: 0.0455 - accuracy: 0.9923 - val_loss: 1.2670 - val_accuracy: 0.6687\n",
            "Epoch 14/25\n",
            "25/25 [==============================] - 8s 303ms/step - loss: 0.0308 - accuracy: 0.9948 - val_loss: 1.3144 - val_accuracy: 0.6687\n",
            "Epoch 15/25\n",
            "25/25 [==============================] - 8s 303ms/step - loss: 0.0383 - accuracy: 0.9910 - val_loss: 1.4619 - val_accuracy: 0.6687\n",
            "Epoch 16/25\n",
            "25/25 [==============================] - 7s 290ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 1.3926 - val_accuracy: 0.6807\n",
            "Epoch 17/25\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.0296 - accuracy: 0.9936 - val_loss: 1.4538 - val_accuracy: 0.6807\n",
            "Epoch 18/25\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0227 - accuracy: 0.9961 - val_loss: 1.3952 - val_accuracy: 0.6627\n",
            "Epoch 19/25\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 1.6724 - val_accuracy: 0.6627\n",
            "Epoch 20/25\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 1.4556 - val_accuracy: 0.6988\n",
            "Epoch 21/25\n",
            "25/25 [==============================] - 7s 289ms/step - loss: 0.0180 - accuracy: 0.9987 - val_loss: 1.5128 - val_accuracy: 0.6807\n",
            "Epoch 22/25\n",
            "25/25 [==============================] - 7s 290ms/step - loss: 0.0262 - accuracy: 0.9936 - val_loss: 1.4500 - val_accuracy: 0.6627\n",
            "Epoch 23/25\n",
            "25/25 [==============================] - 7s 291ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 1.5292 - val_accuracy: 0.6566\n",
            "Epoch 24/25\n",
            "25/25 [==============================] - 7s 291ms/step - loss: 0.0229 - accuracy: 0.9948 - val_loss: 1.7040 - val_accuracy: 0.6627\n",
            "Epoch 25/25\n",
            "25/25 [==============================] - 7s 290ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.6138 - val_accuracy: 0.6687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0PnmTbtBtyC"
      },
      "source": [
        "w/o lr decay, max_len = 200, dim = 128, num_heads = 4, 2 transformer blocksa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg7TAZstALdN"
      },
      "source": [
        "embed_dim = 256  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 256  # Hidden layer size in feed forward network inside transformer\n",
        "nclasses = 12\n",
        "max_length = 200\n",
        "\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_length, MAX_NB_WORDS, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "#x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "\n",
        "outputs = layers.Dense(nclasses, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwmrLx8tAhiX"
      },
      "source": [
        "model.compile('adam', \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYxz8QfjAkBt",
        "outputId": "2e272905-fb3f-4809-f9c3-714e3c61312c"
      },
      "source": [
        "# with 2 transformer blocks\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "25/25 [==============================] - 13s 519ms/step - loss: 2.4088 - accuracy: 0.1366 - val_loss: 2.3828 - val_accuracy: 0.1687\n",
            "Epoch 2/25\n",
            "25/25 [==============================] - 13s 513ms/step - loss: 2.0531 - accuracy: 0.2771 - val_loss: 2.2294 - val_accuracy: 0.1988\n",
            "Epoch 3/25\n",
            "25/25 [==============================] - 12s 498ms/step - loss: 1.5011 - accuracy: 0.4755 - val_loss: 2.2174 - val_accuracy: 0.2410\n",
            "Epoch 4/25\n",
            "25/25 [==============================] - 12s 499ms/step - loss: 0.9994 - accuracy: 0.6521 - val_loss: 1.8183 - val_accuracy: 0.3735\n",
            "Epoch 5/25\n",
            "25/25 [==============================] - 13s 502ms/step - loss: 0.6334 - accuracy: 0.8144 - val_loss: 1.6696 - val_accuracy: 0.4940\n",
            "Epoch 6/25\n",
            "25/25 [==============================] - 13s 501ms/step - loss: 0.4296 - accuracy: 0.8724 - val_loss: 1.8936 - val_accuracy: 0.4578\n",
            "Epoch 7/25\n",
            "25/25 [==============================] - 12s 500ms/step - loss: 0.2388 - accuracy: 0.9317 - val_loss: 1.7391 - val_accuracy: 0.4880\n",
            "Epoch 8/25\n",
            "25/25 [==============================] - 13s 502ms/step - loss: 0.1357 - accuracy: 0.9601 - val_loss: 1.5288 - val_accuracy: 0.5904\n",
            "Epoch 9/25\n",
            "25/25 [==============================] - 12s 499ms/step - loss: 0.0862 - accuracy: 0.9832 - val_loss: 1.6840 - val_accuracy: 0.5120\n",
            "Epoch 10/25\n",
            "25/25 [==============================] - 13s 502ms/step - loss: 0.0607 - accuracy: 0.9858 - val_loss: 1.9233 - val_accuracy: 0.4940\n",
            "Epoch 11/25\n",
            "25/25 [==============================] - 12s 500ms/step - loss: 0.0626 - accuracy: 0.9820 - val_loss: 1.9832 - val_accuracy: 0.5602\n",
            "Epoch 12/25\n",
            "25/25 [==============================] - 12s 498ms/step - loss: 0.0455 - accuracy: 0.9936 - val_loss: 1.8209 - val_accuracy: 0.5964\n",
            "Epoch 13/25\n",
            "25/25 [==============================] - 12s 498ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 1.8620 - val_accuracy: 0.5843\n",
            "Epoch 14/25\n",
            "25/25 [==============================] - 13s 501ms/step - loss: 0.0319 - accuracy: 0.9974 - val_loss: 1.9125 - val_accuracy: 0.5602\n",
            "Epoch 15/25\n",
            "25/25 [==============================] - 12s 500ms/step - loss: 0.0276 - accuracy: 0.9974 - val_loss: 1.8084 - val_accuracy: 0.5602\n",
            "Epoch 16/25\n",
            "25/25 [==============================] - 13s 516ms/step - loss: 0.0215 - accuracy: 0.9987 - val_loss: 2.0985 - val_accuracy: 0.5843\n",
            "Epoch 17/25\n",
            "25/25 [==============================] - 13s 519ms/step - loss: 0.0221 - accuracy: 0.9948 - val_loss: 1.8897 - val_accuracy: 0.5843\n",
            "Epoch 18/25\n",
            "25/25 [==============================] - 13s 503ms/step - loss: 0.0207 - accuracy: 0.9987 - val_loss: 2.0030 - val_accuracy: 0.5602\n",
            "Epoch 19/25\n",
            "25/25 [==============================] - 13s 502ms/step - loss: 0.0210 - accuracy: 0.9974 - val_loss: 2.2728 - val_accuracy: 0.5904\n",
            "Epoch 20/25\n",
            "25/25 [==============================] - 12s 500ms/step - loss: 0.0191 - accuracy: 0.9961 - val_loss: 2.2771 - val_accuracy: 0.5843\n",
            "Epoch 21/25\n",
            "25/25 [==============================] - 13s 501ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 2.1013 - val_accuracy: 0.5783\n",
            "Epoch 22/25\n",
            "25/25 [==============================] - 12s 498ms/step - loss: 0.0206 - accuracy: 0.9974 - val_loss: 2.0552 - val_accuracy: 0.5843\n",
            "Epoch 23/25\n",
            "25/25 [==============================] - 12s 499ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 2.1993 - val_accuracy: 0.5723\n",
            "Epoch 24/25\n",
            "25/25 [==============================] - 12s 499ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 2.2075 - val_accuracy: 0.5542\n",
            "Epoch 25/25\n",
            "25/25 [==============================] - 13s 508ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 2.4300 - val_accuracy: 0.5663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbqBHIfPCIpA"
      },
      "source": [
        "w/o lr decay, max_len = 200, dim = 256, num_heads = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpf03M3pB009"
      },
      "source": [
        "model.compile('adam', \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0orrBZ3QCDyV",
        "outputId": "66e3615b-b93c-4ebc-9374-7617feecee32"
      },
      "source": [
        "\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=25, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "25/25 [==============================] - 16s 632ms/step - loss: 2.4022 - accuracy: 0.1340 - val_loss: 2.3934 - val_accuracy: 0.1566\n",
            "Epoch 2/25\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 2.1571 - accuracy: 0.1534 - val_loss: 2.3931 - val_accuracy: 0.1265\n",
            "Epoch 3/25\n",
            "25/25 [==============================] - 15s 619ms/step - loss: 1.9505 - accuracy: 0.2629 - val_loss: 2.2379 - val_accuracy: 0.1386\n",
            "Epoch 4/25\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 1.6993 - accuracy: 0.3634 - val_loss: 2.2425 - val_accuracy: 0.1988\n",
            "Epoch 5/25\n",
            "25/25 [==============================] - 15s 618ms/step - loss: 1.4831 - accuracy: 0.4536 - val_loss: 2.1491 - val_accuracy: 0.2590\n",
            "Epoch 6/25\n",
            "25/25 [==============================] - 15s 619ms/step - loss: 1.1758 - accuracy: 0.5528 - val_loss: 1.5069 - val_accuracy: 0.4277\n",
            "Epoch 7/25\n",
            "25/25 [==============================] - 15s 619ms/step - loss: 0.9187 - accuracy: 0.6302 - val_loss: 1.6273 - val_accuracy: 0.3916\n",
            "Epoch 8/25\n",
            "25/25 [==============================] - 15s 618ms/step - loss: 0.7206 - accuracy: 0.7178 - val_loss: 1.5534 - val_accuracy: 0.3976\n",
            "Epoch 9/25\n",
            "25/25 [==============================] - 16s 634ms/step - loss: 0.4999 - accuracy: 0.8157 - val_loss: 1.5252 - val_accuracy: 0.5422\n",
            "Epoch 10/25\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.3777 - accuracy: 0.8647 - val_loss: 1.6699 - val_accuracy: 0.5542\n",
            "Epoch 11/25\n",
            "25/25 [==============================] - 15s 618ms/step - loss: 0.2393 - accuracy: 0.9162 - val_loss: 1.4828 - val_accuracy: 0.6265\n",
            "Epoch 12/25\n",
            "25/25 [==============================] - 15s 620ms/step - loss: 0.2261 - accuracy: 0.9278 - val_loss: 2.0488 - val_accuracy: 0.5482\n",
            "Epoch 13/25\n",
            "25/25 [==============================] - 15s 619ms/step - loss: 0.1227 - accuracy: 0.9613 - val_loss: 1.4539 - val_accuracy: 0.6566\n",
            "Epoch 14/25\n",
            "25/25 [==============================] - 15s 620ms/step - loss: 0.0685 - accuracy: 0.9794 - val_loss: 1.9334 - val_accuracy: 0.6265\n",
            "Epoch 15/25\n",
            "25/25 [==============================] - 16s 629ms/step - loss: 0.0538 - accuracy: 0.9845 - val_loss: 1.8531 - val_accuracy: 0.6566\n",
            "Epoch 16/25\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.0376 - accuracy: 0.9910 - val_loss: 2.1189 - val_accuracy: 0.6386\n",
            "Epoch 17/25\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 1.8748 - val_accuracy: 0.6687\n",
            "Epoch 18/25\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.0202 - accuracy: 0.9974 - val_loss: 1.9792 - val_accuracy: 0.6506\n",
            "Epoch 19/25\n",
            "25/25 [==============================] - 15s 620ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 1.8427 - val_accuracy: 0.6627\n",
            "Epoch 20/25\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.0178 - val_accuracy: 0.6386\n",
            "Epoch 21/25\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.0165 - accuracy: 0.9936 - val_loss: 2.0852 - val_accuracy: 0.6627\n",
            "Epoch 22/25\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.0134 - accuracy: 0.9987 - val_loss: 2.2116 - val_accuracy: 0.6867\n",
            "Epoch 23/25\n",
            "25/25 [==============================] - 16s 623ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.4522 - val_accuracy: 0.6506\n",
            "Epoch 24/25\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 2.3399 - val_accuracy: 0.6627\n",
            "Epoch 25/25\n",
            "25/25 [==============================] - 16s 623ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 2.2496 - val_accuracy: 0.6627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0HJ4nwTqwsY"
      },
      "source": [
        "### with glove embedding\n",
        "not working lol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1SCEs3yGHDz",
        "outputId": "c2e68094-2548-463d-b8fb-b7d0b83dbef0"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-23 20:01:16--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-11-23 20:01:16--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-11-23 20:01:16--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.11MB/s    in 6m 28s  \n",
            "\n",
            "2020-11-23 20:07:44 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89OhhPfLuIY6",
        "outputId": "b3e3911f-6934-4c22-ce26-a347e0b89e9b"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.200d.txt  glove.6B.50d.txt\tsample_data\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob59wttXsjVe"
      },
      "source": [
        "import os\n",
        "import pathlib\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgLFrWKouVMm",
        "outputId": "fdffd8f6-5a08-44b8-e58f-a6b4fdebacbe"
      },
      "source": [
        "embeddings_index = {}\n",
        "with open('/content/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQs9FOfouYYS"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    \n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id5Hp8LhutIb"
      },
      "source": [
        "glove_embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            100,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_length,\n",
        "                            trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRoijeRZyZo_",
        "outputId": "b502232c-5f36-4b6c-a2d0-f6f36c302c1b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'embedding_25/embedding_lookup_1/Identity_1:0' shape=(None, 20, 300) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLaIJ5q74cdY"
      },
      "source": [
        "from keras.layers import Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnlzfHwkxo8m",
        "outputId": "b8eff0c7-6594-41bb-83f3-5c316792911a"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "nclasses = 12\n",
        "\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "#print(inputs.shape)\n",
        "embedding_layer = TokenAndPositionEmbedding(max_length, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "print(x.shape)\n",
        "x = glove_embedding_layer(x)\n",
        "print(x.shape)\n",
        "#x = Flatten(x)\n",
        "#print(x.shape)\n",
        "#transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "transformer_block = TransformerBlock(100, num_heads, 100)\n",
        "x = transformer_block(x)\n",
        "print(x.shape)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(nclasses, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 300, 32)\n",
            "(None, 300, 32, 100)\n",
            "(None, 300, 32, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhb19mcAxyRF"
      },
      "source": [
        "model.compile('adam', \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nOI0Ht1x16x",
        "outputId": "4f8e999f-3786-4966-8500-ef15835ea0cd"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train, batch_size=32, epochs=40, validation_data=(X_val_padded, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['token_and_position_embedding_21/embedding_45/embeddings:0', 'token_and_position_embedding_21/embedding_46/embeddings:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['token_and_position_embedding_21/embedding_45/embeddings:0', 'token_and_position_embedding_21/embedding_46/embeddings:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['token_and_position_embedding_21/embedding_45/embeddings:0', 'token_and_position_embedding_21/embedding_46/embeddings:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['token_and_position_embedding_21/embedding_45/embeddings:0', 'token_and_position_embedding_21/embedding_46/embeddings:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QGXLU8wx4Et"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}