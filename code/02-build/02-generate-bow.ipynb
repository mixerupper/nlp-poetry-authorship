{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header initialized\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import janitor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "\n",
    "exec(open(\"../header.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 30\n",
    "data_folder = processed_root(\"02-train-validation-test-split/threshold-\"+str(threshold)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/processed/02-train-validation-test-split/threshold-30/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(data_folder+\"train_data.csv\")\n",
    "val_data = pd.read_csv(data_folder+\"val_data.csv\")\n",
    "test_data = pd.read_csv(data_folder+\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_from_text(texts):\n",
    "    '''\n",
    "    Purpose: Helper function for bag_of_words\n",
    "    Input: texts\n",
    "    Output: list of words that occur in more than threshold texts\n",
    "    '''\n",
    "    \n",
    "    threshold = 5\n",
    "    word_counts = {}\n",
    "    \n",
    "    for text in texts:\n",
    "        for word in text:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1 \n",
    "                \n",
    "    filtered_word_counts = word_counts.copy()\n",
    "\n",
    "    for i in word_counts:\n",
    "        if filtered_word_counts[i] < threshold:\n",
    "            filtered_word_counts.pop(i)\n",
    "            \n",
    "    return list(filtered_word_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(data, text_column):\n",
    "    '''\n",
    "    Purpose: Helper function for bag_of_words\n",
    "    Input: Dataset\n",
    "    Output: array of email sets of words (sets don't allow duplicates)\n",
    "    '''\n",
    "    \n",
    "    return(data.apply(lambda x:set(x[text_column].split(' ')), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {features\\ntoward, Grand, land,\\nremand, heart...\n",
       "1      {of, deep, birds,, vermilion, sweet, play., th...\n",
       "2      {waters.\\nThe, of, not, way, where\\nthis, alwa...\n",
       "3      {my, Hock, thirst, Lip,\\nNor, beg,, not, this,...\n",
       "4      {Wings, noted, –\\n\\nSome, of, Church,\\nOur, ne...\n",
       "                             ...                        \n",
       "452    {of, espionage?, be, destiny., happened, bride...\n",
       "453    {of, though, not, when, thou, stay,\\nAnd, hath...\n",
       "454    {of, woman’s, born, them, upon, whom, what, di...\n",
       "455    {of, that,, lovely, might, way, be, Dr., econo...\n",
       "456    {killing, sacrilege,, of, that,, say'st, honor...\n",
       "Length: 457, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text(train_data, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(data, word_data = None):\n",
    "    '''\n",
    "    Purpose: Converts a dataset to bag of words format.\n",
    "    Input: Dataset\n",
    "    Output: Bag of words version of the data\n",
    "    '''\n",
    "    \n",
    "    texts = extract_text(data, 'content')\n",
    "        \n",
    "    if word_data is None:\n",
    "        bag = extract_words_from_text(texts)\n",
    "    else:\n",
    "        bag = extract_words_from_text(extract_text(word_data, 'content'))\n",
    "    \n",
    "    word_occurence = words_in_texts(bag, texts)\n",
    "    \n",
    "    data = data.reset_index(drop = True)\n",
    "    \n",
    "    new_data = pd.DataFrame(data = word_occurence, columns = bag)\n",
    "    new_data.insert(0, 'poetry_text', data['content'])\n",
    "    new_data['poetry_author'] = data['author']\n",
    "        \n",
    "    return(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    '''\n",
    "    Args:\n",
    "        words (list-like): words to find\n",
    "        texts (Series): sets of words to search in\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
    "        number of texts and p is the number of words.\n",
    "        \n",
    "        Only considers whole words, not partial.\n",
    "    '''\n",
    "    indicator_array = np.array([texts.map(lambda x:word in x) for word in words]).T\n",
    "    return indicator_array.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_train_data = bag_of_words(train_data)\n",
    "bag_val_data = bag_of_words(val_data, word_data = train_data)\n",
    "bag_test_data = bag_of_words(test_data, word_data = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag Train: (457, 1810)\n",
      "Bag Val: (128, 1810)\n",
      "Bag Test: (58, 1810)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag Train:\", bag_train_data.shape)\n",
    "print(\"Bag Val:\", bag_val_data.shape)\n",
    "print(\"Bag Test:\", bag_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datasets(df_dict, save_folder):\n",
    "    for i in df_dict:\n",
    "        try:\n",
    "            df_dict[i].to_csv(save_folder + \"/\" + i, index = False)\n",
    "        except FileNotFoundError:\n",
    "            os.mkdir(save_folder)\n",
    "            df_dict[i].to_csv(save_folder + \"/\" + i, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_to_save = {'bow_train_data.csv':bag_train_data,\n",
    "               'bow_val_data.csv':bag_val_data,\n",
    "               'bow_test_data.csv':bag_test_data}\n",
    "\n",
    "save_datasets(dfs_to_save, save_folder = processed_root(\"03-bag-of-words\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
