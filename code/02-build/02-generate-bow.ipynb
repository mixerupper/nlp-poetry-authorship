{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header initialized\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import janitor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "\n",
    "exec(open(\"../header.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(processed_root(\"02-train-validation-test-split/train_data.csv\"))\n",
    "val_data = pd.read_csv(processed_root(\"02-train-validation-test-split/val_data.csv\"))\n",
    "test_data = pd.read_csv(processed_root(\"02-train-validation-test-split/test_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>poetry_foundation_id</th>\n",
       "      <th>content</th>\n",
       "      <th>author_poem_count</th>\n",
       "      <th>author_poem_index</th>\n",
       "      <th>author_poem_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kay Ryan</td>\n",
       "      <td>Blandeur\\n \\n \\n  \\n   Launch Audio in a New W...</td>\n",
       "      <td>43501</td>\n",
       "      <td>If it please God,\\nlet less happen.\\nEven out ...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Sonnet 98: From you have I been absent in the ...</td>\n",
       "      <td>50503</td>\n",
       "      <td>From you have I been absent in the spring,\\nWh...</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yusef Komunyakaa</td>\n",
       "      <td>A World of Daughters</td>\n",
       "      <td>144600</td>\n",
       "      <td>Say licked clean at birth. Say\\nweeping in the...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily Dickinson</td>\n",
       "      <td>Let me not thirst with this Hock at my Lip</td>\n",
       "      <td>48748</td>\n",
       "      <td>Let me not thirst with this Hock at my Lip,\\nN...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emily Dickinson</td>\n",
       "      <td>Some keep the Sabbath going to Church – (236)</td>\n",
       "      <td>52138</td>\n",
       "      <td>Some keep the Sabbath going to Church –\\nI kee...</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                              title  \\\n",
       "0             Kay Ryan  Blandeur\\n \\n \\n  \\n   Launch Audio in a New W...   \n",
       "1  William Shakespeare  Sonnet 98: From you have I been absent in the ...   \n",
       "2     Yusef Komunyakaa                               A World of Daughters   \n",
       "3      Emily Dickinson         Let me not thirst with this Hock at my Lip   \n",
       "4      Emily Dickinson      Some keep the Sabbath going to Church – (236)   \n",
       "\n",
       "   poetry_foundation_id                                            content  \\\n",
       "0                 43501  If it please God,\\nlet less happen.\\nEven out ...   \n",
       "1                 50503  From you have I been absent in the spring,\\nWh...   \n",
       "2                144600  Say licked clean at birth. Say\\nweeping in the...   \n",
       "3                 48748  Let me not thirst with this Hock at my Lip,\\nN...   \n",
       "4                 52138  Some keep the Sabbath going to Church –\\nI kee...   \n",
       "\n",
       "   author_poem_count  author_poem_index  author_poem_pct  \n",
       "0                 40                  0         0.000000  \n",
       "1                 85                  0         0.000000  \n",
       "2                 43                  0         0.000000  \n",
       "3                 57                  0         0.000000  \n",
       "4                 57                  1         0.017544  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_from_text(texts):\n",
    "    '''\n",
    "    Purpose: Helper function for bag_of_words\n",
    "    Input: texts\n",
    "    Output: list of words that occur in more than threshold texts\n",
    "    '''\n",
    "    \n",
    "    threshold = 5\n",
    "    word_counts = {}\n",
    "    \n",
    "    for text in texts:\n",
    "        for word in text:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1 \n",
    "                \n",
    "    filtered_word_counts = word_counts.copy()\n",
    "\n",
    "    for i in word_counts:\n",
    "        if filtered_word_counts[i] < threshold:\n",
    "            filtered_word_counts.pop(i)\n",
    "            \n",
    "    return list(filtered_word_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(data, text_column):\n",
    "    '''\n",
    "    Purpose: Helper function for bag_of_words\n",
    "    Input: Dataset\n",
    "    Output: array of email sets of words (sets don't allow duplicates)\n",
    "    '''\n",
    "    \n",
    "    return(data.apply(lambda x:set(x[text_column].split(' ')), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {features\\ntoward, Grand, land,\\nremand, heart...\n",
       "1      {of, deep, birds,, vermilion, sweet, play., th...\n",
       "2      {waters.\\nThe, of, not, way, where\\nthis, alwa...\n",
       "3      {my, Hock, thirst, Lip,\\nNor, beg,, not, this,...\n",
       "4      {Wings, noted, –\\n\\nSome, of, Church,\\nOur, ne...\n",
       "                             ...                        \n",
       "452    {of, espionage?, be, destiny., happened, bride...\n",
       "453    {of, though, not, when, thou, stay,\\nAnd, hath...\n",
       "454    {of, woman’s, born, them, upon, whom, what, di...\n",
       "455    {of, that,, lovely, might, way, be, Dr., econo...\n",
       "456    {killing, sacrilege,, of, that,, say'st, honor...\n",
       "Length: 457, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text(train_data, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(data, word_data = None):\n",
    "    '''\n",
    "    Purpose: Converts a dataset to bag of words format.\n",
    "    Input: Dataset\n",
    "    Output: Bag of words version of the data\n",
    "    '''\n",
    "    \n",
    "    texts = extract_text(data, 'content')\n",
    "        \n",
    "    if word_data is None:\n",
    "        bag = extract_words_from_text(texts)\n",
    "    else:\n",
    "        bag = extract_words_from_text(extract_text(word_data, 'content'))\n",
    "    \n",
    "    word_occurence = words_in_texts(bag, texts)\n",
    "    \n",
    "    data = data.reset_index(drop = True)\n",
    "    \n",
    "    new_data = pd.DataFrame(data = word_occurence, columns = bag)\n",
    "    new_data.insert(0, 'poetry_text', data['content'])\n",
    "    new_data['poetry_author'] = data['author']\n",
    "        \n",
    "    return(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    '''\n",
    "    Args:\n",
    "        words (list-like): words to find\n",
    "        texts (Series): sets of words to search in\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
    "        number of texts and p is the number of words.\n",
    "        \n",
    "        Only considers whole words, not partial.\n",
    "    '''\n",
    "    indicator_array = np.array([texts.map(lambda x:word in x) for word in words]).T\n",
    "    return indicator_array.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_train_data = bag_of_words(train_data)\n",
    "bag_val_data = bag_of_words(val_data, word_data = train_data)\n",
    "bag_test_data = bag_of_words(test_data, word_data = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag Train: (457, 1810)\n",
      "Bag Val: (128, 1810)\n",
      "Bag Test: (58, 1810)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag Train:\", bag_train_data.shape)\n",
    "print(\"Bag Val:\", bag_val_data.shape)\n",
    "print(\"Bag Test:\", bag_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datasets(df_dict, save_folder):\n",
    "    for i in df_dict:\n",
    "        try:\n",
    "            df_dict[i].to_csv(save_folder + \"/\" + i, index = False)\n",
    "        except FileNotFoundError:\n",
    "            os.mkdir(save_folder)\n",
    "            df_dict[i].to_csv(save_folder + \"/\" + i, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_to_save = {'bow_train_data.csv':bag_train_data,\n",
    "               'bow_val_data.csv':bag_val_data,\n",
    "               'bow_test_data.csv':bag_test_data}\n",
    "\n",
    "save_datasets(dfs_to_save, save_folder = processed_root(\"03-bag-of-words\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
